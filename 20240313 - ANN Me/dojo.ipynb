{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas;\n",
    "from sklearn.model_selection import train_test_split;\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import InputLayer, Dense, Dropout, BatchNormalization;\n",
    "from tensorflow.keras.regularizers import l2, l1_l2;\n",
    "from tensorflow.keras.utils import plot_model;\n",
    "from tensorflow.keras.callbacks import EarlyStopping;\n",
    "from tensorflow.keras.optimizers import Adam;\n",
    "import matplotlib.pyplot as plt;\n",
    "import numpy;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 381 entries, 0 to 380\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Loan_ID            381 non-null    object \n",
      " 1   Gender             376 non-null    object \n",
      " 2   Married            381 non-null    object \n",
      " 3   Dependents         373 non-null    object \n",
      " 4   Education          381 non-null    object \n",
      " 5   Self_Employed      360 non-null    object \n",
      " 6   ApplicantIncome    381 non-null    int64  \n",
      " 7   CoapplicantIncome  381 non-null    float64\n",
      " 8   LoanAmount         381 non-null    float64\n",
      " 9   Loan_Amount_Term   370 non-null    float64\n",
      " 10  Credit_History     351 non-null    float64\n",
      " 11  Property_Area      381 non-null    object \n",
      " 12  Loan_Status        381 non-null    object \n",
      "dtypes: float64(4), int64(1), object(8)\n",
      "memory usage: 38.8+ KB\n"
     ]
    }
   ],
   "source": [
    "dataframe = pandas.read_csv(\"loan_data.csv\");\n",
    "\n",
    "dataframe.head()\n",
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Initialization\n",
    "\n",
    "THis step pre-process the whole data by encode the data as step below:\n",
    "\n",
    "1. Drop na\n",
    "2. Binary Encode Gender, Self_Employed, Married, Education, and Loan_Status\n",
    "3. Define whole_feature by disclude Loan_ID, and Loan_Status\n",
    "4. Define whole_label by including only Loan_Status\n",
    "\n",
    "Drop Loan_ID and Loan_Status for the whole_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((215, 11), (46, 11), (47, 11), (215,), (46,), (47,))"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = dataframe.dropna();\n",
    "dataframe = dataframe.replace({\n",
    "    \"Gender\": {\"Male\":1,\"Female\" :0},\n",
    "    \"Self_Employed\": {\"Yes\": 1, \"No\": 0},\n",
    "    \"Married\": {\"Yes\": 1, \"No\": 0}, \n",
    "    \"Education\": {\"Graduate\": 1, \"Not Graduate\": 0}, \n",
    "    \"Loan_Status\": {\"Y\": 1, \"N\": 0}\n",
    "});\n",
    "\n",
    "\n",
    "whole_feature = dataframe.drop(columns = [\"Loan_ID\", \"Loan_Status\"]);\n",
    "whole_label = dataframe[\"Loan_Status\"];\n",
    "\n",
    "feature_train, feature_test, label_train, label_test = train_test_split(whole_feature, whole_label, train_size = 0.7, test_size = 0.3, random_state = 42);\n",
    "feature_test, feature_val, label_test, label_val =train_test_split(feature_test, label_test, train_size = 0.5, test_size = 0.5, random_state = 42);\n",
    "\n",
    "feature_train.shape, feature_test.shape, feature_val.shape, label_train.shape, label_test.shape, label_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing\n",
    "\n",
    "1. Perform One-Hot Encoding to Property area and Dependents\n",
    "2. Standard Scaler all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area_Rural</th>\n",
       "      <th>Property_Area_Semiurban</th>\n",
       "      <th>Property_Area_Urban</th>\n",
       "      <th>Dependents_0</th>\n",
       "      <th>Dependents_1</th>\n",
       "      <th>Dependents_2</th>\n",
       "      <th>Dependents_3+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>368</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2297</td>\n",
       "      <td>1522.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>356</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3400</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2698</td>\n",
       "      <td>2034.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Gender  Married  Education  Self_Employed  ApplicantIncome  \\\n",
       "0    368       1        1          1              0             2297   \n",
       "1    356       1        1          1              0             3400   \n",
       "2     89       1        1          1              0             2698   \n",
       "3     19       1        0          0              0             1442   \n",
       "4     12       1        1          0              0             4887   \n",
       "\n",
       "   CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "0             1522.0       104.0             360.0             1.0   \n",
       "1             2500.0       123.0             360.0             0.0   \n",
       "2             2034.0       122.0             360.0             1.0   \n",
       "3                0.0        35.0             360.0             1.0   \n",
       "4                0.0       133.0             360.0             1.0   \n",
       "\n",
       "   Property_Area_Rural  Property_Area_Semiurban  Property_Area_Urban  \\\n",
       "0                  0.0                      0.0                  1.0   \n",
       "1                  1.0                      0.0                  0.0   \n",
       "2                  0.0                      1.0                  0.0   \n",
       "3                  0.0                      0.0                  1.0   \n",
       "4                  1.0                      0.0                  0.0   \n",
       "\n",
       "   Dependents_0  Dependents_1  Dependents_2  Dependents_3+  \n",
       "0           1.0           0.0           0.0            0.0  \n",
       "1           0.0           0.0           0.0            1.0  \n",
       "2           1.0           0.0           0.0            0.0  \n",
       "3           1.0           0.0           0.0            0.0  \n",
       "4           1.0           0.0           0.0            0.0  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder();\n",
    "columns_to_be_encoded = [\"Property_Area\", \"Dependents\"];\n",
    "encoder.fit(feature_train[columns_to_be_encoded]);\n",
    "\n",
    "for i, e in enumerate([feature_train, feature_test, feature_val]):\n",
    "\n",
    "    # Encode the train data first\n",
    "    encoded_property_area = pandas.DataFrame(\n",
    "        encoder.transform(e[columns_to_be_encoded]).toarray(),\n",
    "        columns = encoder.get_feature_names_out()\n",
    "    );\n",
    "\n",
    "    e = e.reset_index();\n",
    "    e = pandas.concat([e, encoded_property_area], axis = 1);\n",
    "\n",
    "    # Drop the original Property_Area column\n",
    "    e = e.drop(columns = columns_to_be_encoded);\n",
    "\n",
    "    if(i == 0):\n",
    "        feature_train = e;\n",
    "    elif(i == 1):\n",
    "        feature_test = e;\n",
    "    else:\n",
    "        feature_val = e;\n",
    "\n",
    "\n",
    "feature_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call out Step 2\n",
    "scaler = StandardScaler();\n",
    "\n",
    "feature_train = scaler.fit_transform(feature_train);\n",
    "feature_test = scaler.fit_transform(feature_test);\n",
    "feature_val = scaler.fit_transform(feature_val);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Training data setup\n",
    "\n",
    "This section will setup all data into float32 numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train = numpy.array(feature_train, dtype = numpy.float32);\n",
    "feature_test = numpy.array(feature_test, dtype = numpy.float32);\n",
    "feature_val = numpy.array(feature_val, dtype = numpy.float32);\n",
    "label_train = numpy.array(label_train, dtype = numpy.float32);\n",
    "label_test = numpy.array(label_test, dtype = numpy.float32);\n",
    "label_val = numpy.array(label_val, dtype = numpy.float32);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNModel():\n",
    "    def __init__(self):\n",
    "        self.input = InputLayer(input_shape = (17,)); # Total input layer is 17\n",
    "\n",
    "        # Hidden Layer 1\n",
    "        self.dense1 = Dense(256, kernel_initializer = \"glorot_uniform\", kernel_regularizer = l2(1e-4));\n",
    "        self.bn1 = BatchNormalization();\n",
    "        self.dropout1 = Dropout(0.5);\n",
    "\n",
    "        self.dense2 = Dense(256, kernel_initializer = \"glorot_uniform\", kernel_regularizer = l2(1e-2));\n",
    "        self.bn2 = BatchNormalization();\n",
    "        self.dropout2 = Dropout(0.5);\n",
    "\n",
    "\n",
    "        self.output = Dense(1, activation = \"sigmoid\", kernel_initializer = \"glorot_uniform\");\n",
    "    \n",
    "    # Early stopping after loss are not improved for some epochs\n",
    "    def _callback_early_stopping(self):\n",
    "        early_stopping_tolerance = 500;\n",
    "\n",
    "        return EarlyStopping(\n",
    "            monitor = \"val_loss\",\n",
    "            patience = early_stopping_tolerance,\n",
    "            restore_best_weights = True\n",
    "        );\n",
    "\n",
    "    def forward(self):\n",
    "        model = Sequential();\n",
    "        \n",
    "        # Construct the model\n",
    "        model.add(self.input);\n",
    "\n",
    "        model.add(self.dense1);\n",
    "        model.add(self.dropout1);\n",
    "        model.add(self.bn1);\n",
    "\n",
    "        model.add(self.dense2);\n",
    "        model.add(self.dropout2);\n",
    "        model.add(self.bn2);\n",
    "\n",
    "        model.add(self.output);\n",
    "\n",
    "        plot_model(model, to_file = (\"model_architecture.png\"), show_shapes = True);\n",
    "        model.summary();\n",
    "        self.model = model;\n",
    "\n",
    "    def fitting(self):\n",
    "        self.forward();\n",
    "\n",
    "        model = self.model;\n",
    "\n",
    "        optimization = Adam(learning_rate = 1e-3);\n",
    "        \n",
    "        model.compile(loss = \"binary_crossentropy\", optimizer = optimization, metrics = \"binary_accuracy\");\n",
    "\n",
    "        history = model.fit(\n",
    "            feature_train, \n",
    "            label_train, \n",
    "            epochs = 10000, \n",
    "            validation_data = (feature_val, label_val), \n",
    "            batch_size = 32,\n",
    "            callbacks = [self._callback_early_stopping()]\n",
    "        );\n",
    "\n",
    "        plt.plot(history.history[\"loss\"], label = \"Model Training Loss\");\n",
    "        plt.plot(history.history[\"val_loss\"], label = \"Model Validation Loss\");\n",
    "        plt.plot(history.history[\"val_binary_accuracy\"], label = \"Model Validation Accuracy (binary_accuracy)\");\n",
    "        plt.title(\"Training and Validation Loss & Accuracy\");\n",
    "        plt.xlabel(\"Epochs\");\n",
    "        plt.ylabel(\"Loss (binary_crossentropy)\");\n",
    "        plt.legend(loc='upper left', bbox_to_anchor=(1, 0.5));\n",
    "        plt.show();\n",
    "\n",
    "        return model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_346 (Dense)           (None, 256)               4608      \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_347 (Dense)           (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_348 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,705\n",
      "Trainable params: 71,681\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "Epoch 1/10000\n",
      "7/7 [==============================] - 1s 51ms/step - loss: 3.3013 - binary_accuracy: 0.5023 - val_loss: 3.0466 - val_binary_accuracy: 0.6809\n",
      "Epoch 2/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.9027 - binary_accuracy: 0.7256 - val_loss: 2.9253 - val_binary_accuracy: 0.7872\n",
      "Epoch 3/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.7657 - binary_accuracy: 0.7302 - val_loss: 2.7890 - val_binary_accuracy: 0.7872\n",
      "Epoch 4/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.5526 - binary_accuracy: 0.8140 - val_loss: 2.6575 - val_binary_accuracy: 0.7872\n",
      "Epoch 5/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.4669 - binary_accuracy: 0.7953 - val_loss: 2.5456 - val_binary_accuracy: 0.7872\n",
      "Epoch 6/10000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 2.3070 - binary_accuracy: 0.7907 - val_loss: 2.4358 - val_binary_accuracy: 0.7872\n",
      "Epoch 7/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.2262 - binary_accuracy: 0.7860 - val_loss: 2.3554 - val_binary_accuracy: 0.7872\n",
      "Epoch 8/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.0955 - binary_accuracy: 0.8140 - val_loss: 2.2672 - val_binary_accuracy: 0.7872\n",
      "Epoch 9/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.0149 - binary_accuracy: 0.8093 - val_loss: 2.1667 - val_binary_accuracy: 0.7872\n",
      "Epoch 10/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.9616 - binary_accuracy: 0.8093 - val_loss: 2.0865 - val_binary_accuracy: 0.7872\n",
      "Epoch 11/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.9019 - binary_accuracy: 0.7860 - val_loss: 1.9968 - val_binary_accuracy: 0.7872\n",
      "Epoch 12/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.8733 - binary_accuracy: 0.7628 - val_loss: 1.9152 - val_binary_accuracy: 0.7872\n",
      "Epoch 13/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.7398 - binary_accuracy: 0.8000 - val_loss: 1.8241 - val_binary_accuracy: 0.7872\n",
      "Epoch 14/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.6831 - binary_accuracy: 0.8093 - val_loss: 1.7668 - val_binary_accuracy: 0.7872\n",
      "Epoch 15/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.5617 - binary_accuracy: 0.8093 - val_loss: 1.7462 - val_binary_accuracy: 0.7872\n",
      "Epoch 16/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.5400 - binary_accuracy: 0.8093 - val_loss: 1.7023 - val_binary_accuracy: 0.7872\n",
      "Epoch 17/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.5410 - binary_accuracy: 0.8000 - val_loss: 1.6665 - val_binary_accuracy: 0.7872\n",
      "Epoch 18/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.3862 - binary_accuracy: 0.8698 - val_loss: 1.6124 - val_binary_accuracy: 0.7872\n",
      "Epoch 19/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.3711 - binary_accuracy: 0.8512 - val_loss: 1.5709 - val_binary_accuracy: 0.7872\n",
      "Epoch 20/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.3931 - binary_accuracy: 0.8047 - val_loss: 1.5140 - val_binary_accuracy: 0.7872\n",
      "Epoch 21/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.3217 - binary_accuracy: 0.8093 - val_loss: 1.4950 - val_binary_accuracy: 0.7872\n",
      "Epoch 22/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2770 - binary_accuracy: 0.8372 - val_loss: 1.4493 - val_binary_accuracy: 0.7872\n",
      "Epoch 23/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.3170 - binary_accuracy: 0.8279 - val_loss: 1.4224 - val_binary_accuracy: 0.7872\n",
      "Epoch 24/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2490 - binary_accuracy: 0.8093 - val_loss: 1.4134 - val_binary_accuracy: 0.7872\n",
      "Epoch 25/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2212 - binary_accuracy: 0.8093 - val_loss: 1.3846 - val_binary_accuracy: 0.7872\n",
      "Epoch 26/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.1917 - binary_accuracy: 0.8279 - val_loss: 1.3530 - val_binary_accuracy: 0.7872\n",
      "Epoch 27/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2061 - binary_accuracy: 0.8093 - val_loss: 1.3155 - val_binary_accuracy: 0.7872\n",
      "Epoch 28/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.0883 - binary_accuracy: 0.8372 - val_loss: 1.2875 - val_binary_accuracy: 0.7872\n",
      "Epoch 29/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.1328 - binary_accuracy: 0.8233 - val_loss: 1.2728 - val_binary_accuracy: 0.7872\n",
      "Epoch 30/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.1029 - binary_accuracy: 0.8372 - val_loss: 1.2704 - val_binary_accuracy: 0.7872\n",
      "Epoch 31/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0800 - binary_accuracy: 0.7907 - val_loss: 1.2294 - val_binary_accuracy: 0.7872\n",
      "Epoch 32/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0776 - binary_accuracy: 0.8233 - val_loss: 1.1984 - val_binary_accuracy: 0.7872\n",
      "Epoch 33/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.9837 - binary_accuracy: 0.8558 - val_loss: 1.2090 - val_binary_accuracy: 0.7872\n",
      "Epoch 34/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9644 - binary_accuracy: 0.8279 - val_loss: 1.1811 - val_binary_accuracy: 0.7872\n",
      "Epoch 35/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9254 - binary_accuracy: 0.8605 - val_loss: 1.1702 - val_binary_accuracy: 0.7872\n",
      "Epoch 36/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9307 - binary_accuracy: 0.8233 - val_loss: 1.1649 - val_binary_accuracy: 0.7872\n",
      "Epoch 37/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9414 - binary_accuracy: 0.8140 - val_loss: 1.1499 - val_binary_accuracy: 0.7872\n",
      "Epoch 38/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9273 - binary_accuracy: 0.8326 - val_loss: 1.1400 - val_binary_accuracy: 0.7872\n",
      "Epoch 39/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9164 - binary_accuracy: 0.8233 - val_loss: 1.1488 - val_binary_accuracy: 0.7872\n",
      "Epoch 40/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8874 - binary_accuracy: 0.8512 - val_loss: 1.1560 - val_binary_accuracy: 0.7872\n",
      "Epoch 41/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8488 - binary_accuracy: 0.8419 - val_loss: 1.0910 - val_binary_accuracy: 0.7872\n",
      "Epoch 42/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.8662 - binary_accuracy: 0.8186 - val_loss: 1.0426 - val_binary_accuracy: 0.7872\n",
      "Epoch 43/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8505 - binary_accuracy: 0.8419 - val_loss: 1.0372 - val_binary_accuracy: 0.7872\n",
      "Epoch 44/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8086 - binary_accuracy: 0.8512 - val_loss: 1.0267 - val_binary_accuracy: 0.7872\n",
      "Epoch 45/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8300 - binary_accuracy: 0.8279 - val_loss: 1.0072 - val_binary_accuracy: 0.7872\n",
      "Epoch 46/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7862 - binary_accuracy: 0.8326 - val_loss: 1.0161 - val_binary_accuracy: 0.7872\n",
      "Epoch 47/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7395 - binary_accuracy: 0.8326 - val_loss: 1.0244 - val_binary_accuracy: 0.7872\n",
      "Epoch 48/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7649 - binary_accuracy: 0.8233 - val_loss: 1.0226 - val_binary_accuracy: 0.7872\n",
      "Epoch 49/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7531 - binary_accuracy: 0.8326 - val_loss: 0.9967 - val_binary_accuracy: 0.7872\n",
      "Epoch 50/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7446 - binary_accuracy: 0.8419 - val_loss: 0.9874 - val_binary_accuracy: 0.7872\n",
      "Epoch 51/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7572 - binary_accuracy: 0.8605 - val_loss: 1.0036 - val_binary_accuracy: 0.7872\n",
      "Epoch 52/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6917 - binary_accuracy: 0.8326 - val_loss: 1.0145 - val_binary_accuracy: 0.7872\n",
      "Epoch 53/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7349 - binary_accuracy: 0.8512 - val_loss: 1.0024 - val_binary_accuracy: 0.7872\n",
      "Epoch 54/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7307 - binary_accuracy: 0.8233 - val_loss: 0.9758 - val_binary_accuracy: 0.7872\n",
      "Epoch 55/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6992 - binary_accuracy: 0.8651 - val_loss: 0.9490 - val_binary_accuracy: 0.7872\n",
      "Epoch 56/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6906 - binary_accuracy: 0.8186 - val_loss: 0.9410 - val_binary_accuracy: 0.7872\n",
      "Epoch 57/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6983 - binary_accuracy: 0.8233 - val_loss: 0.9415 - val_binary_accuracy: 0.7872\n",
      "Epoch 58/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6633 - binary_accuracy: 0.8326 - val_loss: 0.9213 - val_binary_accuracy: 0.7872\n",
      "Epoch 59/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6424 - binary_accuracy: 0.8558 - val_loss: 0.9150 - val_binary_accuracy: 0.7872\n",
      "Epoch 60/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6834 - binary_accuracy: 0.8419 - val_loss: 0.9162 - val_binary_accuracy: 0.7872\n",
      "Epoch 61/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6295 - binary_accuracy: 0.8419 - val_loss: 0.9299 - val_binary_accuracy: 0.7872\n",
      "Epoch 62/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6470 - binary_accuracy: 0.8372 - val_loss: 0.9112 - val_binary_accuracy: 0.7872\n",
      "Epoch 63/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6409 - binary_accuracy: 0.8558 - val_loss: 0.8779 - val_binary_accuracy: 0.7872\n",
      "Epoch 64/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6630 - binary_accuracy: 0.8093 - val_loss: 0.8702 - val_binary_accuracy: 0.7872\n",
      "Epoch 65/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6124 - binary_accuracy: 0.8372 - val_loss: 0.8640 - val_binary_accuracy: 0.7872\n",
      "Epoch 66/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5961 - binary_accuracy: 0.8465 - val_loss: 0.8585 - val_binary_accuracy: 0.7872\n",
      "Epoch 67/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5699 - binary_accuracy: 0.8465 - val_loss: 0.8643 - val_binary_accuracy: 0.7872\n",
      "Epoch 68/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5752 - binary_accuracy: 0.8372 - val_loss: 0.8879 - val_binary_accuracy: 0.7872\n",
      "Epoch 69/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5965 - binary_accuracy: 0.8372 - val_loss: 0.8854 - val_binary_accuracy: 0.7872\n",
      "Epoch 70/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5934 - binary_accuracy: 0.8326 - val_loss: 0.8744 - val_binary_accuracy: 0.7872\n",
      "Epoch 71/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5372 - binary_accuracy: 0.8465 - val_loss: 0.8796 - val_binary_accuracy: 0.7872\n",
      "Epoch 72/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5927 - binary_accuracy: 0.8140 - val_loss: 0.8793 - val_binary_accuracy: 0.7872\n",
      "Epoch 73/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6016 - binary_accuracy: 0.8186 - val_loss: 0.8502 - val_binary_accuracy: 0.7872\n",
      "Epoch 74/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5931 - binary_accuracy: 0.8326 - val_loss: 0.8206 - val_binary_accuracy: 0.7872\n",
      "Epoch 75/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5939 - binary_accuracy: 0.8372 - val_loss: 0.8262 - val_binary_accuracy: 0.7872\n",
      "Epoch 76/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5956 - binary_accuracy: 0.8140 - val_loss: 0.8185 - val_binary_accuracy: 0.7872\n",
      "Epoch 77/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5600 - binary_accuracy: 0.8651 - val_loss: 0.8137 - val_binary_accuracy: 0.7872\n",
      "Epoch 78/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5432 - binary_accuracy: 0.8326 - val_loss: 0.8321 - val_binary_accuracy: 0.7872\n",
      "Epoch 79/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5396 - binary_accuracy: 0.8465 - val_loss: 0.8530 - val_binary_accuracy: 0.7872\n",
      "Epoch 80/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5371 - binary_accuracy: 0.8372 - val_loss: 0.8446 - val_binary_accuracy: 0.7872\n",
      "Epoch 81/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5410 - binary_accuracy: 0.8558 - val_loss: 0.8370 - val_binary_accuracy: 0.7872\n",
      "Epoch 82/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.5021 - binary_accuracy: 0.8279 - val_loss: 0.8369 - val_binary_accuracy: 0.7872\n",
      "Epoch 83/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5389 - binary_accuracy: 0.8512 - val_loss: 0.8398 - val_binary_accuracy: 0.7872\n",
      "Epoch 84/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4994 - binary_accuracy: 0.8651 - val_loss: 0.8173 - val_binary_accuracy: 0.7872\n",
      "Epoch 85/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5708 - binary_accuracy: 0.8186 - val_loss: 0.7968 - val_binary_accuracy: 0.7872\n",
      "Epoch 86/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5246 - binary_accuracy: 0.8326 - val_loss: 0.8029 - val_binary_accuracy: 0.7872\n",
      "Epoch 87/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5368 - binary_accuracy: 0.8233 - val_loss: 0.7928 - val_binary_accuracy: 0.7872\n",
      "Epoch 88/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5028 - binary_accuracy: 0.8465 - val_loss: 0.7850 - val_binary_accuracy: 0.7872\n",
      "Epoch 89/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5288 - binary_accuracy: 0.8512 - val_loss: 0.7966 - val_binary_accuracy: 0.7872\n",
      "Epoch 90/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4795 - binary_accuracy: 0.8605 - val_loss: 0.7926 - val_binary_accuracy: 0.7872\n",
      "Epoch 91/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4999 - binary_accuracy: 0.8326 - val_loss: 0.7981 - val_binary_accuracy: 0.7872\n",
      "Epoch 92/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5038 - binary_accuracy: 0.8512 - val_loss: 0.8147 - val_binary_accuracy: 0.7872\n",
      "Epoch 93/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5164 - binary_accuracy: 0.8465 - val_loss: 0.8007 - val_binary_accuracy: 0.7872\n",
      "Epoch 94/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5158 - binary_accuracy: 0.8279 - val_loss: 0.8115 - val_binary_accuracy: 0.7872\n",
      "Epoch 95/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4781 - binary_accuracy: 0.8512 - val_loss: 0.8034 - val_binary_accuracy: 0.7872\n",
      "Epoch 96/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4952 - binary_accuracy: 0.8279 - val_loss: 0.7966 - val_binary_accuracy: 0.7872\n",
      "Epoch 97/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4816 - binary_accuracy: 0.8419 - val_loss: 0.7862 - val_binary_accuracy: 0.7872\n",
      "Epoch 98/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.5062 - binary_accuracy: 0.8605 - val_loss: 0.7773 - val_binary_accuracy: 0.7872\n",
      "Epoch 99/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4960 - binary_accuracy: 0.8419 - val_loss: 0.7756 - val_binary_accuracy: 0.7872\n",
      "Epoch 100/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4795 - binary_accuracy: 0.8419 - val_loss: 0.7817 - val_binary_accuracy: 0.7872\n",
      "Epoch 101/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4550 - binary_accuracy: 0.8698 - val_loss: 0.7825 - val_binary_accuracy: 0.7872\n",
      "Epoch 102/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4955 - binary_accuracy: 0.8465 - val_loss: 0.7920 - val_binary_accuracy: 0.7872\n",
      "Epoch 103/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4633 - binary_accuracy: 0.8512 - val_loss: 0.7998 - val_binary_accuracy: 0.7872\n",
      "Epoch 104/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4688 - binary_accuracy: 0.8326 - val_loss: 0.8053 - val_binary_accuracy: 0.7872\n",
      "Epoch 105/10000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4888 - binary_accuracy: 0.8465 - val_loss: 0.7923 - val_binary_accuracy: 0.7872\n",
      "Epoch 106/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4810 - binary_accuracy: 0.8372 - val_loss: 0.7909 - val_binary_accuracy: 0.7872\n",
      "Epoch 107/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4786 - binary_accuracy: 0.8372 - val_loss: 0.7839 - val_binary_accuracy: 0.7872\n",
      "Epoch 108/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4918 - binary_accuracy: 0.8372 - val_loss: 0.7497 - val_binary_accuracy: 0.7872\n",
      "Epoch 109/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4613 - binary_accuracy: 0.8605 - val_loss: 0.7313 - val_binary_accuracy: 0.7872\n",
      "Epoch 110/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4638 - binary_accuracy: 0.8372 - val_loss: 0.7316 - val_binary_accuracy: 0.7872\n",
      "Epoch 111/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5051 - binary_accuracy: 0.8512 - val_loss: 0.7392 - val_binary_accuracy: 0.7872\n",
      "Epoch 112/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4583 - binary_accuracy: 0.8698 - val_loss: 0.7336 - val_binary_accuracy: 0.7872\n",
      "Epoch 113/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4724 - binary_accuracy: 0.8465 - val_loss: 0.7471 - val_binary_accuracy: 0.7872\n",
      "Epoch 114/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4440 - binary_accuracy: 0.8651 - val_loss: 0.7763 - val_binary_accuracy: 0.7872\n",
      "Epoch 115/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4898 - binary_accuracy: 0.8279 - val_loss: 0.7726 - val_binary_accuracy: 0.7872\n",
      "Epoch 116/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4914 - binary_accuracy: 0.8419 - val_loss: 0.7564 - val_binary_accuracy: 0.7872\n",
      "Epoch 117/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4661 - binary_accuracy: 0.8512 - val_loss: 0.7468 - val_binary_accuracy: 0.7872\n",
      "Epoch 118/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4611 - binary_accuracy: 0.8419 - val_loss: 0.7464 - val_binary_accuracy: 0.7872\n",
      "Epoch 119/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4832 - binary_accuracy: 0.8512 - val_loss: 0.7392 - val_binary_accuracy: 0.7872\n",
      "Epoch 120/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4475 - binary_accuracy: 0.8512 - val_loss: 0.7248 - val_binary_accuracy: 0.7872\n",
      "Epoch 121/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4571 - binary_accuracy: 0.8465 - val_loss: 0.7159 - val_binary_accuracy: 0.7872\n",
      "Epoch 122/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4221 - binary_accuracy: 0.8465 - val_loss: 0.7345 - val_binary_accuracy: 0.7872\n",
      "Epoch 123/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4554 - binary_accuracy: 0.8512 - val_loss: 0.7453 - val_binary_accuracy: 0.7872\n",
      "Epoch 124/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4325 - binary_accuracy: 0.8512 - val_loss: 0.7676 - val_binary_accuracy: 0.7872\n",
      "Epoch 125/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4604 - binary_accuracy: 0.8419 - val_loss: 0.7705 - val_binary_accuracy: 0.7872\n",
      "Epoch 126/10000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4301 - binary_accuracy: 0.8791 - val_loss: 0.7729 - val_binary_accuracy: 0.7872\n",
      "Epoch 127/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4261 - binary_accuracy: 0.8465 - val_loss: 0.7747 - val_binary_accuracy: 0.7872\n",
      "Epoch 128/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4697 - binary_accuracy: 0.8419 - val_loss: 0.7671 - val_binary_accuracy: 0.7872\n",
      "Epoch 129/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4214 - binary_accuracy: 0.8512 - val_loss: 0.7712 - val_binary_accuracy: 0.7872\n",
      "Epoch 130/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4664 - binary_accuracy: 0.8512 - val_loss: 0.7740 - val_binary_accuracy: 0.7872\n",
      "Epoch 131/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4527 - binary_accuracy: 0.8279 - val_loss: 0.7507 - val_binary_accuracy: 0.7872\n",
      "Epoch 132/10000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4220 - binary_accuracy: 0.8605 - val_loss: 0.7264 - val_binary_accuracy: 0.7872\n",
      "Epoch 133/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4504 - binary_accuracy: 0.8465 - val_loss: 0.7055 - val_binary_accuracy: 0.7872\n",
      "Epoch 134/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4400 - binary_accuracy: 0.8605 - val_loss: 0.7113 - val_binary_accuracy: 0.7872\n",
      "Epoch 135/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4545 - binary_accuracy: 0.8233 - val_loss: 0.7193 - val_binary_accuracy: 0.7872\n",
      "Epoch 136/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4337 - binary_accuracy: 0.8605 - val_loss: 0.7417 - val_binary_accuracy: 0.7872\n",
      "Epoch 137/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4315 - binary_accuracy: 0.8605 - val_loss: 0.7630 - val_binary_accuracy: 0.7872\n",
      "Epoch 138/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4834 - binary_accuracy: 0.8186 - val_loss: 0.7368 - val_binary_accuracy: 0.7872\n",
      "Epoch 139/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4516 - binary_accuracy: 0.8558 - val_loss: 0.7168 - val_binary_accuracy: 0.7872\n",
      "Epoch 140/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4484 - binary_accuracy: 0.8512 - val_loss: 0.7123 - val_binary_accuracy: 0.7872\n",
      "Epoch 141/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4367 - binary_accuracy: 0.8419 - val_loss: 0.7233 - val_binary_accuracy: 0.7872\n",
      "Epoch 142/10000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4304 - binary_accuracy: 0.8651 - val_loss: 0.7364 - val_binary_accuracy: 0.7872\n",
      "Epoch 143/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4288 - binary_accuracy: 0.8605 - val_loss: 0.7480 - val_binary_accuracy: 0.7872\n",
      "Epoch 144/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4441 - binary_accuracy: 0.8326 - val_loss: 0.7478 - val_binary_accuracy: 0.7872\n",
      "Epoch 145/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4118 - binary_accuracy: 0.8558 - val_loss: 0.7570 - val_binary_accuracy: 0.7872\n",
      "Epoch 146/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4241 - binary_accuracy: 0.8605 - val_loss: 0.7672 - val_binary_accuracy: 0.7872\n",
      "Epoch 147/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4264 - binary_accuracy: 0.8512 - val_loss: 0.7786 - val_binary_accuracy: 0.7872\n",
      "Epoch 148/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4224 - binary_accuracy: 0.8605 - val_loss: 0.7804 - val_binary_accuracy: 0.7872\n",
      "Epoch 149/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4231 - binary_accuracy: 0.8558 - val_loss: 0.7661 - val_binary_accuracy: 0.7872\n",
      "Epoch 150/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4855 - binary_accuracy: 0.8186 - val_loss: 0.7300 - val_binary_accuracy: 0.7872\n",
      "Epoch 151/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4191 - binary_accuracy: 0.8512 - val_loss: 0.7099 - val_binary_accuracy: 0.7872\n",
      "Epoch 152/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4206 - binary_accuracy: 0.8605 - val_loss: 0.7128 - val_binary_accuracy: 0.7872\n",
      "Epoch 153/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4022 - binary_accuracy: 0.8465 - val_loss: 0.7343 - val_binary_accuracy: 0.7872\n",
      "Epoch 154/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4479 - binary_accuracy: 0.8465 - val_loss: 0.7507 - val_binary_accuracy: 0.7872\n",
      "Epoch 155/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4225 - binary_accuracy: 0.8512 - val_loss: 0.7598 - val_binary_accuracy: 0.7872\n",
      "Epoch 156/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4267 - binary_accuracy: 0.8465 - val_loss: 0.7530 - val_binary_accuracy: 0.7872\n",
      "Epoch 157/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4385 - binary_accuracy: 0.8419 - val_loss: 0.7638 - val_binary_accuracy: 0.7872\n",
      "Epoch 158/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3971 - binary_accuracy: 0.8558 - val_loss: 0.7705 - val_binary_accuracy: 0.7872\n",
      "Epoch 159/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4160 - binary_accuracy: 0.8419 - val_loss: 0.7699 - val_binary_accuracy: 0.7872\n",
      "Epoch 160/10000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4764 - binary_accuracy: 0.8326 - val_loss: 0.7523 - val_binary_accuracy: 0.7872\n",
      "Epoch 161/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4116 - binary_accuracy: 0.8512 - val_loss: 0.7332 - val_binary_accuracy: 0.7872\n",
      "Epoch 162/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4233 - binary_accuracy: 0.8465 - val_loss: 0.7421 - val_binary_accuracy: 0.7872\n",
      "Epoch 163/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4532 - binary_accuracy: 0.8372 - val_loss: 0.7475 - val_binary_accuracy: 0.7872\n",
      "Epoch 164/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4294 - binary_accuracy: 0.8605 - val_loss: 0.7442 - val_binary_accuracy: 0.7872\n",
      "Epoch 165/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4063 - binary_accuracy: 0.8512 - val_loss: 0.7512 - val_binary_accuracy: 0.7872\n",
      "Epoch 166/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4205 - binary_accuracy: 0.8558 - val_loss: 0.7459 - val_binary_accuracy: 0.7872\n",
      "Epoch 167/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3748 - binary_accuracy: 0.8698 - val_loss: 0.7580 - val_binary_accuracy: 0.7872\n",
      "Epoch 168/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3965 - binary_accuracy: 0.8558 - val_loss: 0.7605 - val_binary_accuracy: 0.7872\n",
      "Epoch 169/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4214 - binary_accuracy: 0.8419 - val_loss: 0.7718 - val_binary_accuracy: 0.7872\n",
      "Epoch 170/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4253 - binary_accuracy: 0.8326 - val_loss: 0.7489 - val_binary_accuracy: 0.7872\n",
      "Epoch 171/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4407 - binary_accuracy: 0.8419 - val_loss: 0.7170 - val_binary_accuracy: 0.7872\n",
      "Epoch 172/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4475 - binary_accuracy: 0.8233 - val_loss: 0.7206 - val_binary_accuracy: 0.7872\n",
      "Epoch 173/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4483 - binary_accuracy: 0.8465 - val_loss: 0.7257 - val_binary_accuracy: 0.7872\n",
      "Epoch 174/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4080 - binary_accuracy: 0.8558 - val_loss: 0.7187 - val_binary_accuracy: 0.7872\n",
      "Epoch 175/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4176 - binary_accuracy: 0.8651 - val_loss: 0.7118 - val_binary_accuracy: 0.7872\n",
      "Epoch 176/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4295 - binary_accuracy: 0.8512 - val_loss: 0.7166 - val_binary_accuracy: 0.7872\n",
      "Epoch 177/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4426 - binary_accuracy: 0.8465 - val_loss: 0.7036 - val_binary_accuracy: 0.7872\n",
      "Epoch 178/10000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4035 - binary_accuracy: 0.8512 - val_loss: 0.7094 - val_binary_accuracy: 0.7872\n",
      "Epoch 179/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4130 - binary_accuracy: 0.8558 - val_loss: 0.7184 - val_binary_accuracy: 0.7872\n",
      "Epoch 180/10000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4065 - binary_accuracy: 0.8605 - val_loss: 0.7140 - val_binary_accuracy: 0.7872\n",
      "Epoch 181/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3968 - binary_accuracy: 0.8465 - val_loss: 0.7398 - val_binary_accuracy: 0.7872\n",
      "Epoch 182/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4062 - binary_accuracy: 0.8558 - val_loss: 0.7763 - val_binary_accuracy: 0.7872\n",
      "Epoch 183/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4231 - binary_accuracy: 0.8512 - val_loss: 0.7602 - val_binary_accuracy: 0.7872\n",
      "Epoch 184/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4069 - binary_accuracy: 0.8558 - val_loss: 0.7431 - val_binary_accuracy: 0.7872\n",
      "Epoch 185/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4048 - binary_accuracy: 0.8465 - val_loss: 0.7171 - val_binary_accuracy: 0.7872\n",
      "Epoch 186/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4144 - binary_accuracy: 0.8326 - val_loss: 0.7143 - val_binary_accuracy: 0.7872\n",
      "Epoch 187/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4281 - binary_accuracy: 0.8372 - val_loss: 0.7038 - val_binary_accuracy: 0.7872\n",
      "Epoch 188/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4035 - binary_accuracy: 0.8512 - val_loss: 0.7018 - val_binary_accuracy: 0.7872\n",
      "Epoch 189/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4396 - binary_accuracy: 0.8512 - val_loss: 0.7244 - val_binary_accuracy: 0.7872\n",
      "Epoch 190/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3971 - binary_accuracy: 0.8651 - val_loss: 0.7480 - val_binary_accuracy: 0.7872\n",
      "Epoch 191/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4070 - binary_accuracy: 0.8651 - val_loss: 0.7628 - val_binary_accuracy: 0.7872\n",
      "Epoch 192/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4371 - binary_accuracy: 0.8326 - val_loss: 0.7507 - val_binary_accuracy: 0.7872\n",
      "Epoch 193/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4212 - binary_accuracy: 0.8326 - val_loss: 0.7247 - val_binary_accuracy: 0.7872\n",
      "Epoch 194/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3806 - binary_accuracy: 0.8791 - val_loss: 0.7244 - val_binary_accuracy: 0.7872\n",
      "Epoch 195/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4316 - binary_accuracy: 0.8419 - val_loss: 0.7225 - val_binary_accuracy: 0.7872\n",
      "Epoch 196/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4209 - binary_accuracy: 0.8465 - val_loss: 0.7306 - val_binary_accuracy: 0.7872\n",
      "Epoch 197/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4120 - binary_accuracy: 0.8605 - val_loss: 0.7507 - val_binary_accuracy: 0.7872\n",
      "Epoch 198/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4093 - binary_accuracy: 0.8558 - val_loss: 0.7509 - val_binary_accuracy: 0.7872\n",
      "Epoch 199/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4246 - binary_accuracy: 0.8512 - val_loss: 0.7328 - val_binary_accuracy: 0.7872\n",
      "Epoch 200/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4086 - binary_accuracy: 0.8512 - val_loss: 0.7421 - val_binary_accuracy: 0.7872\n",
      "Epoch 201/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4269 - binary_accuracy: 0.8605 - val_loss: 0.7286 - val_binary_accuracy: 0.7872\n",
      "Epoch 202/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4196 - binary_accuracy: 0.8651 - val_loss: 0.7124 - val_binary_accuracy: 0.7872\n",
      "Epoch 203/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4233 - binary_accuracy: 0.8605 - val_loss: 0.7287 - val_binary_accuracy: 0.7872\n",
      "Epoch 204/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4337 - binary_accuracy: 0.8465 - val_loss: 0.7366 - val_binary_accuracy: 0.7872\n",
      "Epoch 205/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3999 - binary_accuracy: 0.8558 - val_loss: 0.7487 - val_binary_accuracy: 0.7872\n",
      "Epoch 206/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3949 - binary_accuracy: 0.8605 - val_loss: 0.7577 - val_binary_accuracy: 0.7872\n",
      "Epoch 207/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4092 - binary_accuracy: 0.8512 - val_loss: 0.7603 - val_binary_accuracy: 0.7872\n",
      "Epoch 208/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4221 - binary_accuracy: 0.8512 - val_loss: 0.7573 - val_binary_accuracy: 0.7872\n",
      "Epoch 209/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4365 - binary_accuracy: 0.8419 - val_loss: 0.7419 - val_binary_accuracy: 0.7872\n",
      "Epoch 210/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3967 - binary_accuracy: 0.8744 - val_loss: 0.7298 - val_binary_accuracy: 0.7872\n",
      "Epoch 211/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4058 - binary_accuracy: 0.8651 - val_loss: 0.7083 - val_binary_accuracy: 0.7872\n",
      "Epoch 212/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4211 - binary_accuracy: 0.8512 - val_loss: 0.6992 - val_binary_accuracy: 0.7872\n",
      "Epoch 213/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4113 - binary_accuracy: 0.8326 - val_loss: 0.7119 - val_binary_accuracy: 0.7872\n",
      "Epoch 214/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4313 - binary_accuracy: 0.8233 - val_loss: 0.7218 - val_binary_accuracy: 0.7872\n",
      "Epoch 215/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4037 - binary_accuracy: 0.8605 - val_loss: 0.7383 - val_binary_accuracy: 0.7872\n",
      "Epoch 216/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4028 - binary_accuracy: 0.8558 - val_loss: 0.7377 - val_binary_accuracy: 0.7872\n",
      "Epoch 217/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4144 - binary_accuracy: 0.8419 - val_loss: 0.7301 - val_binary_accuracy: 0.7872\n",
      "Epoch 218/10000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3953 - binary_accuracy: 0.8419 - val_loss: 0.7381 - val_binary_accuracy: 0.7872\n",
      "Epoch 219/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4299 - binary_accuracy: 0.8372 - val_loss: 0.7377 - val_binary_accuracy: 0.7872\n",
      "Epoch 220/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4073 - binary_accuracy: 0.8465 - val_loss: 0.7328 - val_binary_accuracy: 0.7872\n",
      "Epoch 221/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4018 - binary_accuracy: 0.8465 - val_loss: 0.7371 - val_binary_accuracy: 0.7872\n",
      "Epoch 222/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4048 - binary_accuracy: 0.8558 - val_loss: 0.7156 - val_binary_accuracy: 0.7872\n",
      "Epoch 223/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4093 - binary_accuracy: 0.8512 - val_loss: 0.7062 - val_binary_accuracy: 0.7872\n",
      "Epoch 224/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4003 - binary_accuracy: 0.8512 - val_loss: 0.7143 - val_binary_accuracy: 0.7872\n",
      "Epoch 225/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4322 - binary_accuracy: 0.8186 - val_loss: 0.7210 - val_binary_accuracy: 0.7872\n",
      "Epoch 226/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4231 - binary_accuracy: 0.8465 - val_loss: 0.7257 - val_binary_accuracy: 0.7872\n",
      "Epoch 227/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3903 - binary_accuracy: 0.8512 - val_loss: 0.7296 - val_binary_accuracy: 0.7872\n",
      "Epoch 228/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3809 - binary_accuracy: 0.8744 - val_loss: 0.7579 - val_binary_accuracy: 0.7872\n",
      "Epoch 229/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4174 - binary_accuracy: 0.8512 - val_loss: 0.7797 - val_binary_accuracy: 0.7872\n",
      "Epoch 230/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3901 - binary_accuracy: 0.8372 - val_loss: 0.7725 - val_binary_accuracy: 0.7872\n",
      "Epoch 231/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4040 - binary_accuracy: 0.8605 - val_loss: 0.7552 - val_binary_accuracy: 0.7872\n",
      "Epoch 232/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3786 - binary_accuracy: 0.8512 - val_loss: 0.7454 - val_binary_accuracy: 0.7872\n",
      "Epoch 233/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4003 - binary_accuracy: 0.8558 - val_loss: 0.7493 - val_binary_accuracy: 0.7872\n",
      "Epoch 234/10000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4274 - binary_accuracy: 0.8605 - val_loss: 0.7376 - val_binary_accuracy: 0.7872\n",
      "Epoch 235/10000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4106 - binary_accuracy: 0.8512 - val_loss: 0.7519 - val_binary_accuracy: 0.7872\n",
      "Epoch 236/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4360 - binary_accuracy: 0.8279 - val_loss: 0.7359 - val_binary_accuracy: 0.7872\n",
      "Epoch 237/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4147 - binary_accuracy: 0.8512 - val_loss: 0.7290 - val_binary_accuracy: 0.7872\n",
      "Epoch 238/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3985 - binary_accuracy: 0.8372 - val_loss: 0.7138 - val_binary_accuracy: 0.7872\n",
      "Epoch 239/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4101 - binary_accuracy: 0.8558 - val_loss: 0.7197 - val_binary_accuracy: 0.7872\n",
      "Epoch 240/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4200 - binary_accuracy: 0.8419 - val_loss: 0.7223 - val_binary_accuracy: 0.7872\n",
      "Epoch 241/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4213 - binary_accuracy: 0.8326 - val_loss: 0.7063 - val_binary_accuracy: 0.7872\n",
      "Epoch 242/10000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3854 - binary_accuracy: 0.8698 - val_loss: 0.7100 - val_binary_accuracy: 0.7872\n",
      "Epoch 243/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4130 - binary_accuracy: 0.8512 - val_loss: 0.7056 - val_binary_accuracy: 0.7872\n",
      "Epoch 244/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4155 - binary_accuracy: 0.8605 - val_loss: 0.7089 - val_binary_accuracy: 0.7872\n",
      "Epoch 245/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4014 - binary_accuracy: 0.8512 - val_loss: 0.7123 - val_binary_accuracy: 0.7872\n",
      "Epoch 246/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4025 - binary_accuracy: 0.8651 - val_loss: 0.7132 - val_binary_accuracy: 0.7872\n",
      "Epoch 247/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3776 - binary_accuracy: 0.8605 - val_loss: 0.7405 - val_binary_accuracy: 0.7872\n",
      "Epoch 248/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3964 - binary_accuracy: 0.8419 - val_loss: 0.7590 - val_binary_accuracy: 0.7872\n",
      "Epoch 249/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3985 - binary_accuracy: 0.8558 - val_loss: 0.7482 - val_binary_accuracy: 0.7872\n",
      "Epoch 250/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4191 - binary_accuracy: 0.8326 - val_loss: 0.7409 - val_binary_accuracy: 0.7872\n",
      "Epoch 251/10000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4238 - binary_accuracy: 0.8558 - val_loss: 0.7331 - val_binary_accuracy: 0.7872\n",
      "Epoch 252/10000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4098 - binary_accuracy: 0.8605 - val_loss: 0.7282 - val_binary_accuracy: 0.7872\n",
      "Epoch 253/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4243 - binary_accuracy: 0.8465 - val_loss: 0.7123 - val_binary_accuracy: 0.7872\n",
      "Epoch 254/10000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4156 - binary_accuracy: 0.8558 - val_loss: 0.7124 - val_binary_accuracy: 0.7872\n",
      "Epoch 255/10000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3855 - binary_accuracy: 0.8605 - val_loss: 0.7199 - val_binary_accuracy: 0.7872\n",
      "Epoch 256/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4222 - binary_accuracy: 0.8558 - val_loss: 0.7179 - val_binary_accuracy: 0.7872\n",
      "Epoch 257/10000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4171 - binary_accuracy: 0.8419 - val_loss: 0.7185 - val_binary_accuracy: 0.7872\n",
      "Epoch 258/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4003 - binary_accuracy: 0.8930 - val_loss: 0.7444 - val_binary_accuracy: 0.7872\n",
      "Epoch 259/10000\n",
      "7/7 [==============================] - 0s 47ms/step - loss: 0.3828 - binary_accuracy: 0.8651 - val_loss: 0.7799 - val_binary_accuracy: 0.7872\n",
      "Epoch 260/10000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4111 - binary_accuracy: 0.8465 - val_loss: 0.7904 - val_binary_accuracy: 0.7872\n",
      "Epoch 261/10000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3858 - binary_accuracy: 0.8465 - val_loss: 0.7786 - val_binary_accuracy: 0.7872\n",
      "Epoch 262/10000\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.4253 - binary_accuracy: 0.8419 - val_loss: 0.7535 - val_binary_accuracy: 0.7872\n",
      "Epoch 263/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4146 - binary_accuracy: 0.8465 - val_loss: 0.7519 - val_binary_accuracy: 0.7872\n",
      "Epoch 264/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4012 - binary_accuracy: 0.8419 - val_loss: 0.7403 - val_binary_accuracy: 0.7872\n",
      "Epoch 265/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4143 - binary_accuracy: 0.8512 - val_loss: 0.7393 - val_binary_accuracy: 0.7872\n",
      "Epoch 266/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3833 - binary_accuracy: 0.8465 - val_loss: 0.7664 - val_binary_accuracy: 0.7872\n",
      "Epoch 267/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3861 - binary_accuracy: 0.8698 - val_loss: 0.7796 - val_binary_accuracy: 0.7872\n",
      "Epoch 268/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4271 - binary_accuracy: 0.8558 - val_loss: 0.7886 - val_binary_accuracy: 0.7872\n",
      "Epoch 269/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4013 - binary_accuracy: 0.8558 - val_loss: 0.7720 - val_binary_accuracy: 0.7872\n",
      "Epoch 270/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4192 - binary_accuracy: 0.8558 - val_loss: 0.7666 - val_binary_accuracy: 0.7872\n",
      "Epoch 271/10000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3936 - binary_accuracy: 0.8465 - val_loss: 0.7504 - val_binary_accuracy: 0.7872\n",
      "Epoch 272/10000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4062 - binary_accuracy: 0.8372 - val_loss: 0.7572 - val_binary_accuracy: 0.7872\n",
      "Epoch 273/10000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.4177 - binary_accuracy: 0.8326 - val_loss: 0.7366 - val_binary_accuracy: 0.7872\n",
      "Epoch 274/10000\n",
      "7/7 [==============================] - 0s 45ms/step - loss: 0.4130 - binary_accuracy: 0.8605 - val_loss: 0.7521 - val_binary_accuracy: 0.7872\n",
      "Epoch 275/10000\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.4124 - binary_accuracy: 0.8419 - val_loss: 0.7318 - val_binary_accuracy: 0.7872\n",
      "Epoch 276/10000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3832 - binary_accuracy: 0.8651 - val_loss: 0.7301 - val_binary_accuracy: 0.7872\n",
      "Epoch 277/10000\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.3818 - binary_accuracy: 0.8512 - val_loss: 0.7403 - val_binary_accuracy: 0.7872\n",
      "Epoch 278/10000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.3717 - binary_accuracy: 0.8605 - val_loss: 0.7601 - val_binary_accuracy: 0.7872\n",
      "Epoch 279/10000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.4076 - binary_accuracy: 0.8372 - val_loss: 0.7435 - val_binary_accuracy: 0.7872\n",
      "Epoch 280/10000\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.3977 - binary_accuracy: 0.8419 - val_loss: 0.7424 - val_binary_accuracy: 0.7872\n",
      "Epoch 281/10000\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.4176 - binary_accuracy: 0.8605 - val_loss: 0.7401 - val_binary_accuracy: 0.7872\n",
      "Epoch 282/10000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.3975 - binary_accuracy: 0.8465 - val_loss: 0.7395 - val_binary_accuracy: 0.7872\n",
      "Epoch 283/10000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.4215 - binary_accuracy: 0.8326 - val_loss: 0.7199 - val_binary_accuracy: 0.7872\n",
      "Epoch 284/10000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3816 - binary_accuracy: 0.8698 - val_loss: 0.7426 - val_binary_accuracy: 0.7872\n",
      "Epoch 285/10000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.4134 - binary_accuracy: 0.8558 - val_loss: 0.7459 - val_binary_accuracy: 0.7872\n",
      "Epoch 286/10000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4240 - binary_accuracy: 0.8465 - val_loss: 0.7512 - val_binary_accuracy: 0.7872\n",
      "Epoch 287/10000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4040 - binary_accuracy: 0.8512 - val_loss: 0.7532 - val_binary_accuracy: 0.7872\n",
      "Epoch 288/10000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3853 - binary_accuracy: 0.8605 - val_loss: 0.7471 - val_binary_accuracy: 0.7872\n",
      "Epoch 289/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4101 - binary_accuracy: 0.8558 - val_loss: 0.7321 - val_binary_accuracy: 0.7872\n",
      "Epoch 290/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3847 - binary_accuracy: 0.8744 - val_loss: 0.7429 - val_binary_accuracy: 0.7872\n",
      "Epoch 291/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3728 - binary_accuracy: 0.8837 - val_loss: 0.7728 - val_binary_accuracy: 0.7872\n",
      "Epoch 292/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3983 - binary_accuracy: 0.8372 - val_loss: 0.7677 - val_binary_accuracy: 0.7872\n",
      "Epoch 293/10000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4131 - binary_accuracy: 0.8465 - val_loss: 0.7536 - val_binary_accuracy: 0.7872\n",
      "Epoch 294/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4148 - binary_accuracy: 0.8512 - val_loss: 0.7511 - val_binary_accuracy: 0.7872\n",
      "Epoch 295/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3800 - binary_accuracy: 0.8512 - val_loss: 0.7377 - val_binary_accuracy: 0.7872\n",
      "Epoch 296/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4251 - binary_accuracy: 0.8419 - val_loss: 0.7404 - val_binary_accuracy: 0.7872\n",
      "Epoch 297/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4002 - binary_accuracy: 0.8512 - val_loss: 0.7237 - val_binary_accuracy: 0.7872\n",
      "Epoch 298/10000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4050 - binary_accuracy: 0.8465 - val_loss: 0.7295 - val_binary_accuracy: 0.7872\n",
      "Epoch 299/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3795 - binary_accuracy: 0.8744 - val_loss: 0.7437 - val_binary_accuracy: 0.7872\n",
      "Epoch 300/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3980 - binary_accuracy: 0.8512 - val_loss: 0.7537 - val_binary_accuracy: 0.7872\n",
      "Epoch 301/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4362 - binary_accuracy: 0.8372 - val_loss: 0.7395 - val_binary_accuracy: 0.7872\n",
      "Epoch 302/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3800 - binary_accuracy: 0.8651 - val_loss: 0.7437 - val_binary_accuracy: 0.7872\n",
      "Epoch 303/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4256 - binary_accuracy: 0.8465 - val_loss: 0.7573 - val_binary_accuracy: 0.7872\n",
      "Epoch 304/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3697 - binary_accuracy: 0.8744 - val_loss: 0.7408 - val_binary_accuracy: 0.7872\n",
      "Epoch 305/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4207 - binary_accuracy: 0.8279 - val_loss: 0.7350 - val_binary_accuracy: 0.7872\n",
      "Epoch 306/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4214 - binary_accuracy: 0.8651 - val_loss: 0.7097 - val_binary_accuracy: 0.7872\n",
      "Epoch 307/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4118 - binary_accuracy: 0.8605 - val_loss: 0.7226 - val_binary_accuracy: 0.7872\n",
      "Epoch 308/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3894 - binary_accuracy: 0.8605 - val_loss: 0.7391 - val_binary_accuracy: 0.7872\n",
      "Epoch 309/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4054 - binary_accuracy: 0.8419 - val_loss: 0.7456 - val_binary_accuracy: 0.7872\n",
      "Epoch 310/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3934 - binary_accuracy: 0.8698 - val_loss: 0.7562 - val_binary_accuracy: 0.7872\n",
      "Epoch 311/10000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4052 - binary_accuracy: 0.8372 - val_loss: 0.7352 - val_binary_accuracy: 0.7872\n",
      "Epoch 312/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3923 - binary_accuracy: 0.8698 - val_loss: 0.7213 - val_binary_accuracy: 0.7872\n",
      "Epoch 313/10000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4192 - binary_accuracy: 0.8512 - val_loss: 0.7254 - val_binary_accuracy: 0.7872\n",
      "Epoch 314/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4090 - binary_accuracy: 0.8558 - val_loss: 0.7273 - val_binary_accuracy: 0.7872\n",
      "Epoch 315/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3767 - binary_accuracy: 0.8605 - val_loss: 0.7236 - val_binary_accuracy: 0.7872\n",
      "Epoch 316/10000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3895 - binary_accuracy: 0.8651 - val_loss: 0.7364 - val_binary_accuracy: 0.7872\n",
      "Epoch 317/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3956 - binary_accuracy: 0.8698 - val_loss: 0.7420 - val_binary_accuracy: 0.7872\n",
      "Epoch 318/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3988 - binary_accuracy: 0.8744 - val_loss: 0.7614 - val_binary_accuracy: 0.7872\n",
      "Epoch 319/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4039 - binary_accuracy: 0.8326 - val_loss: 0.7553 - val_binary_accuracy: 0.7872\n",
      "Epoch 320/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3891 - binary_accuracy: 0.8558 - val_loss: 0.7416 - val_binary_accuracy: 0.7872\n",
      "Epoch 321/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4194 - binary_accuracy: 0.8465 - val_loss: 0.7351 - val_binary_accuracy: 0.7872\n",
      "Epoch 322/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4095 - binary_accuracy: 0.8465 - val_loss: 0.7338 - val_binary_accuracy: 0.7872\n",
      "Epoch 323/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4102 - binary_accuracy: 0.8558 - val_loss: 0.7333 - val_binary_accuracy: 0.7872\n",
      "Epoch 324/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3862 - binary_accuracy: 0.8512 - val_loss: 0.7371 - val_binary_accuracy: 0.7872\n",
      "Epoch 325/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3923 - binary_accuracy: 0.8512 - val_loss: 0.7417 - val_binary_accuracy: 0.7872\n",
      "Epoch 326/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4013 - binary_accuracy: 0.8419 - val_loss: 0.7465 - val_binary_accuracy: 0.7872\n",
      "Epoch 327/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4174 - binary_accuracy: 0.8419 - val_loss: 0.7391 - val_binary_accuracy: 0.7872\n",
      "Epoch 328/10000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3896 - binary_accuracy: 0.8512 - val_loss: 0.7208 - val_binary_accuracy: 0.7872\n",
      "Epoch 329/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4240 - binary_accuracy: 0.8465 - val_loss: 0.7134 - val_binary_accuracy: 0.7872\n",
      "Epoch 330/10000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3705 - binary_accuracy: 0.8605 - val_loss: 0.7138 - val_binary_accuracy: 0.7872\n",
      "Epoch 331/10000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4190 - binary_accuracy: 0.8326 - val_loss: 0.7273 - val_binary_accuracy: 0.7872\n",
      "Epoch 332/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3972 - binary_accuracy: 0.8512 - val_loss: 0.7487 - val_binary_accuracy: 0.7872\n",
      "Epoch 333/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4266 - binary_accuracy: 0.8465 - val_loss: 0.7426 - val_binary_accuracy: 0.7872\n",
      "Epoch 334/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3859 - binary_accuracy: 0.8698 - val_loss: 0.7495 - val_binary_accuracy: 0.7872\n",
      "Epoch 335/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4066 - binary_accuracy: 0.8651 - val_loss: 0.7265 - val_binary_accuracy: 0.7872\n",
      "Epoch 336/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4081 - binary_accuracy: 0.8512 - val_loss: 0.7284 - val_binary_accuracy: 0.7872\n",
      "Epoch 337/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3917 - binary_accuracy: 0.8419 - val_loss: 0.7453 - val_binary_accuracy: 0.7872\n",
      "Epoch 338/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3827 - binary_accuracy: 0.8605 - val_loss: 0.7359 - val_binary_accuracy: 0.7872\n",
      "Epoch 339/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4233 - binary_accuracy: 0.8465 - val_loss: 0.7303 - val_binary_accuracy: 0.7872\n",
      "Epoch 340/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3908 - binary_accuracy: 0.8698 - val_loss: 0.7237 - val_binary_accuracy: 0.7872\n",
      "Epoch 341/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3956 - binary_accuracy: 0.8558 - val_loss: 0.7440 - val_binary_accuracy: 0.7872\n",
      "Epoch 342/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3877 - binary_accuracy: 0.8698 - val_loss: 0.7383 - val_binary_accuracy: 0.7872\n",
      "Epoch 343/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4152 - binary_accuracy: 0.8512 - val_loss: 0.7249 - val_binary_accuracy: 0.7872\n",
      "Epoch 344/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4166 - binary_accuracy: 0.8419 - val_loss: 0.7402 - val_binary_accuracy: 0.7872\n",
      "Epoch 345/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4038 - binary_accuracy: 0.8512 - val_loss: 0.7420 - val_binary_accuracy: 0.7872\n",
      "Epoch 346/10000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3915 - binary_accuracy: 0.8651 - val_loss: 0.7424 - val_binary_accuracy: 0.7872\n",
      "Epoch 347/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3674 - binary_accuracy: 0.8465 - val_loss: 0.7355 - val_binary_accuracy: 0.7872\n",
      "Epoch 348/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4360 - binary_accuracy: 0.8419 - val_loss: 0.7147 - val_binary_accuracy: 0.7872\n",
      "Epoch 349/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4002 - binary_accuracy: 0.8651 - val_loss: 0.6953 - val_binary_accuracy: 0.7872\n",
      "Epoch 350/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4160 - binary_accuracy: 0.8465 - val_loss: 0.6854 - val_binary_accuracy: 0.7872\n",
      "Epoch 351/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4204 - binary_accuracy: 0.8372 - val_loss: 0.7050 - val_binary_accuracy: 0.7872\n",
      "Epoch 352/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4124 - binary_accuracy: 0.8512 - val_loss: 0.7270 - val_binary_accuracy: 0.7872\n",
      "Epoch 353/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4127 - binary_accuracy: 0.8605 - val_loss: 0.7349 - val_binary_accuracy: 0.7872\n",
      "Epoch 354/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3810 - binary_accuracy: 0.8465 - val_loss: 0.7360 - val_binary_accuracy: 0.7872\n",
      "Epoch 355/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3846 - binary_accuracy: 0.8605 - val_loss: 0.7336 - val_binary_accuracy: 0.7872\n",
      "Epoch 356/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4151 - binary_accuracy: 0.8372 - val_loss: 0.7344 - val_binary_accuracy: 0.7872\n",
      "Epoch 357/10000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4060 - binary_accuracy: 0.8698 - val_loss: 0.7358 - val_binary_accuracy: 0.7872\n",
      "Epoch 358/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3999 - binary_accuracy: 0.8558 - val_loss: 0.7284 - val_binary_accuracy: 0.7872\n",
      "Epoch 359/10000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4005 - binary_accuracy: 0.8465 - val_loss: 0.7293 - val_binary_accuracy: 0.7872\n",
      "Epoch 360/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4010 - binary_accuracy: 0.8651 - val_loss: 0.7299 - val_binary_accuracy: 0.7872\n",
      "Epoch 361/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4096 - binary_accuracy: 0.8558 - val_loss: 0.7311 - val_binary_accuracy: 0.7872\n",
      "Epoch 362/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4005 - binary_accuracy: 0.8512 - val_loss: 0.7285 - val_binary_accuracy: 0.7872\n",
      "Epoch 363/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3799 - binary_accuracy: 0.8512 - val_loss: 0.7538 - val_binary_accuracy: 0.7872\n",
      "Epoch 364/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4162 - binary_accuracy: 0.8465 - val_loss: 0.7646 - val_binary_accuracy: 0.7872\n",
      "Epoch 365/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4097 - binary_accuracy: 0.8419 - val_loss: 0.7682 - val_binary_accuracy: 0.7872\n",
      "Epoch 366/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3727 - binary_accuracy: 0.8744 - val_loss: 0.7637 - val_binary_accuracy: 0.7872\n",
      "Epoch 367/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3968 - binary_accuracy: 0.8465 - val_loss: 0.7459 - val_binary_accuracy: 0.7872\n",
      "Epoch 368/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4193 - binary_accuracy: 0.8326 - val_loss: 0.7129 - val_binary_accuracy: 0.7872\n",
      "Epoch 369/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4075 - binary_accuracy: 0.8419 - val_loss: 0.7160 - val_binary_accuracy: 0.7872\n",
      "Epoch 370/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3748 - binary_accuracy: 0.8512 - val_loss: 0.7236 - val_binary_accuracy: 0.7872\n",
      "Epoch 371/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3947 - binary_accuracy: 0.8651 - val_loss: 0.7529 - val_binary_accuracy: 0.7872\n",
      "Epoch 372/10000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3969 - binary_accuracy: 0.8512 - val_loss: 0.7492 - val_binary_accuracy: 0.7872\n",
      "Epoch 373/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3945 - binary_accuracy: 0.8651 - val_loss: 0.7347 - val_binary_accuracy: 0.7872\n",
      "Epoch 374/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3898 - binary_accuracy: 0.8698 - val_loss: 0.7359 - val_binary_accuracy: 0.7872\n",
      "Epoch 375/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4068 - binary_accuracy: 0.8605 - val_loss: 0.7511 - val_binary_accuracy: 0.7872\n",
      "Epoch 376/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4123 - binary_accuracy: 0.8512 - val_loss: 0.7524 - val_binary_accuracy: 0.7872\n",
      "Epoch 377/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3855 - binary_accuracy: 0.8651 - val_loss: 0.7511 - val_binary_accuracy: 0.7872\n",
      "Epoch 378/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4088 - binary_accuracy: 0.8884 - val_loss: 0.7466 - val_binary_accuracy: 0.7872\n",
      "Epoch 379/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4131 - binary_accuracy: 0.8512 - val_loss: 0.7640 - val_binary_accuracy: 0.7872\n",
      "Epoch 380/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3896 - binary_accuracy: 0.8605 - val_loss: 0.7685 - val_binary_accuracy: 0.7872\n",
      "Epoch 381/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4099 - binary_accuracy: 0.8698 - val_loss: 0.7646 - val_binary_accuracy: 0.7872\n",
      "Epoch 382/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4042 - binary_accuracy: 0.8326 - val_loss: 0.7338 - val_binary_accuracy: 0.7872\n",
      "Epoch 383/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4049 - binary_accuracy: 0.8419 - val_loss: 0.7190 - val_binary_accuracy: 0.7872\n",
      "Epoch 384/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3960 - binary_accuracy: 0.8512 - val_loss: 0.7148 - val_binary_accuracy: 0.7872\n",
      "Epoch 385/10000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4159 - binary_accuracy: 0.8558 - val_loss: 0.7030 - val_binary_accuracy: 0.7872\n",
      "Epoch 386/10000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3849 - binary_accuracy: 0.8558 - val_loss: 0.7254 - val_binary_accuracy: 0.7872\n",
      "Epoch 387/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4062 - binary_accuracy: 0.8233 - val_loss: 0.7239 - val_binary_accuracy: 0.7872\n",
      "Epoch 388/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3754 - binary_accuracy: 0.8558 - val_loss: 0.7367 - val_binary_accuracy: 0.7872\n",
      "Epoch 389/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4184 - binary_accuracy: 0.8465 - val_loss: 0.7368 - val_binary_accuracy: 0.7872\n",
      "Epoch 390/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3712 - binary_accuracy: 0.8744 - val_loss: 0.7402 - val_binary_accuracy: 0.7872\n",
      "Epoch 391/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4159 - binary_accuracy: 0.8465 - val_loss: 0.7359 - val_binary_accuracy: 0.7872\n",
      "Epoch 392/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4169 - binary_accuracy: 0.8512 - val_loss: 0.7528 - val_binary_accuracy: 0.7872\n",
      "Epoch 393/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3909 - binary_accuracy: 0.8698 - val_loss: 0.7442 - val_binary_accuracy: 0.7872\n",
      "Epoch 394/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4078 - binary_accuracy: 0.8558 - val_loss: 0.7211 - val_binary_accuracy: 0.7872\n",
      "Epoch 395/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4024 - binary_accuracy: 0.8605 - val_loss: 0.7216 - val_binary_accuracy: 0.7872\n",
      "Epoch 396/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4095 - binary_accuracy: 0.8326 - val_loss: 0.7379 - val_binary_accuracy: 0.7872\n",
      "Epoch 397/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4033 - binary_accuracy: 0.8605 - val_loss: 0.7456 - val_binary_accuracy: 0.7872\n",
      "Epoch 398/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4157 - binary_accuracy: 0.8512 - val_loss: 0.7384 - val_binary_accuracy: 0.7872\n",
      "Epoch 399/10000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3737 - binary_accuracy: 0.8651 - val_loss: 0.7222 - val_binary_accuracy: 0.7872\n",
      "Epoch 400/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4048 - binary_accuracy: 0.8512 - val_loss: 0.7175 - val_binary_accuracy: 0.7872\n",
      "Epoch 401/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3956 - binary_accuracy: 0.8651 - val_loss: 0.7175 - val_binary_accuracy: 0.7872\n",
      "Epoch 402/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3835 - binary_accuracy: 0.8512 - val_loss: 0.7596 - val_binary_accuracy: 0.7872\n",
      "Epoch 403/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3985 - binary_accuracy: 0.8512 - val_loss: 0.7654 - val_binary_accuracy: 0.7872\n",
      "Epoch 404/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3961 - binary_accuracy: 0.8419 - val_loss: 0.7583 - val_binary_accuracy: 0.7872\n",
      "Epoch 405/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4164 - binary_accuracy: 0.8465 - val_loss: 0.7463 - val_binary_accuracy: 0.7872\n",
      "Epoch 406/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4076 - binary_accuracy: 0.8419 - val_loss: 0.7316 - val_binary_accuracy: 0.7872\n",
      "Epoch 407/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3777 - binary_accuracy: 0.8558 - val_loss: 0.7267 - val_binary_accuracy: 0.7872\n",
      "Epoch 408/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4109 - binary_accuracy: 0.8372 - val_loss: 0.7241 - val_binary_accuracy: 0.7872\n",
      "Epoch 409/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4050 - binary_accuracy: 0.8558 - val_loss: 0.7162 - val_binary_accuracy: 0.7872\n",
      "Epoch 410/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3845 - binary_accuracy: 0.8512 - val_loss: 0.7442 - val_binary_accuracy: 0.7872\n",
      "Epoch 411/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4601 - binary_accuracy: 0.8233 - val_loss: 0.7378 - val_binary_accuracy: 0.7872\n",
      "Epoch 412/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4026 - binary_accuracy: 0.8419 - val_loss: 0.7116 - val_binary_accuracy: 0.7872\n",
      "Epoch 413/10000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3811 - binary_accuracy: 0.8651 - val_loss: 0.7041 - val_binary_accuracy: 0.7872\n",
      "Epoch 414/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4000 - binary_accuracy: 0.8512 - val_loss: 0.6989 - val_binary_accuracy: 0.7872\n",
      "Epoch 415/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4090 - binary_accuracy: 0.8512 - val_loss: 0.7389 - val_binary_accuracy: 0.7872\n",
      "Epoch 416/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3980 - binary_accuracy: 0.8605 - val_loss: 0.7588 - val_binary_accuracy: 0.7872\n",
      "Epoch 417/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3919 - binary_accuracy: 0.8419 - val_loss: 0.7521 - val_binary_accuracy: 0.7872\n",
      "Epoch 418/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3769 - binary_accuracy: 0.8419 - val_loss: 0.7579 - val_binary_accuracy: 0.7872\n",
      "Epoch 419/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3880 - binary_accuracy: 0.8419 - val_loss: 0.7592 - val_binary_accuracy: 0.7872\n",
      "Epoch 420/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3984 - binary_accuracy: 0.8512 - val_loss: 0.7539 - val_binary_accuracy: 0.7872\n",
      "Epoch 421/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4169 - binary_accuracy: 0.8512 - val_loss: 0.7349 - val_binary_accuracy: 0.7872\n",
      "Epoch 422/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4007 - binary_accuracy: 0.8419 - val_loss: 0.7237 - val_binary_accuracy: 0.7872\n",
      "Epoch 423/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3739 - binary_accuracy: 0.8558 - val_loss: 0.7309 - val_binary_accuracy: 0.7872\n",
      "Epoch 424/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4356 - binary_accuracy: 0.8233 - val_loss: 0.7343 - val_binary_accuracy: 0.7872\n",
      "Epoch 425/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3744 - binary_accuracy: 0.8512 - val_loss: 0.6992 - val_binary_accuracy: 0.7872\n",
      "Epoch 426/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4407 - binary_accuracy: 0.8233 - val_loss: 0.6900 - val_binary_accuracy: 0.7872\n",
      "Epoch 427/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4242 - binary_accuracy: 0.8605 - val_loss: 0.6959 - val_binary_accuracy: 0.7872\n",
      "Epoch 428/10000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3691 - binary_accuracy: 0.8791 - val_loss: 0.7363 - val_binary_accuracy: 0.7872\n",
      "Epoch 429/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3769 - binary_accuracy: 0.8651 - val_loss: 0.7853 - val_binary_accuracy: 0.7872\n",
      "Epoch 430/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3966 - binary_accuracy: 0.8465 - val_loss: 0.8181 - val_binary_accuracy: 0.7872\n",
      "Epoch 431/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3844 - binary_accuracy: 0.8605 - val_loss: 0.8040 - val_binary_accuracy: 0.7872\n",
      "Epoch 432/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4008 - binary_accuracy: 0.8465 - val_loss: 0.7857 - val_binary_accuracy: 0.7872\n",
      "Epoch 433/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3900 - binary_accuracy: 0.8372 - val_loss: 0.7685 - val_binary_accuracy: 0.7872\n",
      "Epoch 434/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4288 - binary_accuracy: 0.8186 - val_loss: 0.7525 - val_binary_accuracy: 0.7872\n",
      "Epoch 435/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4094 - binary_accuracy: 0.8279 - val_loss: 0.7164 - val_binary_accuracy: 0.7872\n",
      "Epoch 436/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3771 - binary_accuracy: 0.8651 - val_loss: 0.6984 - val_binary_accuracy: 0.7872\n",
      "Epoch 437/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3947 - binary_accuracy: 0.8512 - val_loss: 0.7079 - val_binary_accuracy: 0.7872\n",
      "Epoch 438/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4164 - binary_accuracy: 0.8651 - val_loss: 0.7149 - val_binary_accuracy: 0.7872\n",
      "Epoch 439/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4111 - binary_accuracy: 0.8465 - val_loss: 0.6967 - val_binary_accuracy: 0.7872\n",
      "Epoch 440/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3678 - binary_accuracy: 0.8698 - val_loss: 0.7280 - val_binary_accuracy: 0.7872\n",
      "Epoch 441/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4111 - binary_accuracy: 0.8279 - val_loss: 0.7545 - val_binary_accuracy: 0.7872\n",
      "Epoch 442/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3844 - binary_accuracy: 0.8558 - val_loss: 0.7614 - val_binary_accuracy: 0.7872\n",
      "Epoch 443/10000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4020 - binary_accuracy: 0.8558 - val_loss: 0.7581 - val_binary_accuracy: 0.7872\n",
      "Epoch 444/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3989 - binary_accuracy: 0.8558 - val_loss: 0.7567 - val_binary_accuracy: 0.7872\n",
      "Epoch 445/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3909 - binary_accuracy: 0.8605 - val_loss: 0.7592 - val_binary_accuracy: 0.7872\n",
      "Epoch 446/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3782 - binary_accuracy: 0.8605 - val_loss: 0.7573 - val_binary_accuracy: 0.7872\n",
      "Epoch 447/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3910 - binary_accuracy: 0.8651 - val_loss: 0.7574 - val_binary_accuracy: 0.7872\n",
      "Epoch 448/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4120 - binary_accuracy: 0.8419 - val_loss: 0.7735 - val_binary_accuracy: 0.7872\n",
      "Epoch 449/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4181 - binary_accuracy: 0.8279 - val_loss: 0.7885 - val_binary_accuracy: 0.7872\n",
      "Epoch 450/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4191 - binary_accuracy: 0.8512 - val_loss: 0.7657 - val_binary_accuracy: 0.7872\n",
      "Epoch 451/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3985 - binary_accuracy: 0.8651 - val_loss: 0.7399 - val_binary_accuracy: 0.7872\n",
      "Epoch 452/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3906 - binary_accuracy: 0.8605 - val_loss: 0.7429 - val_binary_accuracy: 0.7872\n",
      "Epoch 453/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3903 - binary_accuracy: 0.8419 - val_loss: 0.7586 - val_binary_accuracy: 0.7872\n",
      "Epoch 454/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4027 - binary_accuracy: 0.8605 - val_loss: 0.7683 - val_binary_accuracy: 0.7872\n",
      "Epoch 455/10000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4113 - binary_accuracy: 0.8465 - val_loss: 0.7661 - val_binary_accuracy: 0.7872\n",
      "Epoch 456/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3844 - binary_accuracy: 0.8698 - val_loss: 0.7704 - val_binary_accuracy: 0.7872\n",
      "Epoch 457/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4231 - binary_accuracy: 0.8186 - val_loss: 0.7492 - val_binary_accuracy: 0.7872\n",
      "Epoch 458/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3840 - binary_accuracy: 0.8698 - val_loss: 0.7576 - val_binary_accuracy: 0.7872\n",
      "Epoch 459/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3981 - binary_accuracy: 0.8465 - val_loss: 0.7551 - val_binary_accuracy: 0.7872\n",
      "Epoch 460/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4130 - binary_accuracy: 0.8558 - val_loss: 0.7640 - val_binary_accuracy: 0.7872\n",
      "Epoch 461/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4046 - binary_accuracy: 0.8419 - val_loss: 0.7688 - val_binary_accuracy: 0.7872\n",
      "Epoch 462/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4173 - binary_accuracy: 0.8651 - val_loss: 0.7613 - val_binary_accuracy: 0.7872\n",
      "Epoch 463/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4094 - binary_accuracy: 0.8465 - val_loss: 0.7597 - val_binary_accuracy: 0.7872\n",
      "Epoch 464/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3770 - binary_accuracy: 0.8512 - val_loss: 0.7797 - val_binary_accuracy: 0.7872\n",
      "Epoch 465/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3947 - binary_accuracy: 0.8698 - val_loss: 0.7796 - val_binary_accuracy: 0.7872\n",
      "Epoch 466/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4297 - binary_accuracy: 0.8605 - val_loss: 0.7769 - val_binary_accuracy: 0.7872\n",
      "Epoch 467/10000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.3676 - binary_accuracy: 0.8837 - val_loss: 0.7549 - val_binary_accuracy: 0.7872\n",
      "Epoch 468/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4070 - binary_accuracy: 0.8512 - val_loss: 0.7415 - val_binary_accuracy: 0.7872\n",
      "Epoch 469/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4104 - binary_accuracy: 0.8512 - val_loss: 0.7401 - val_binary_accuracy: 0.7872\n",
      "Epoch 470/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3679 - binary_accuracy: 0.8605 - val_loss: 0.6996 - val_binary_accuracy: 0.7872\n",
      "Epoch 471/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4054 - binary_accuracy: 0.8465 - val_loss: 0.6979 - val_binary_accuracy: 0.7872\n",
      "Epoch 472/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3921 - binary_accuracy: 0.8512 - val_loss: 0.6998 - val_binary_accuracy: 0.7872\n",
      "Epoch 473/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4161 - binary_accuracy: 0.8419 - val_loss: 0.7046 - val_binary_accuracy: 0.7872\n",
      "Epoch 474/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3881 - binary_accuracy: 0.8651 - val_loss: 0.7244 - val_binary_accuracy: 0.7872\n",
      "Epoch 475/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4162 - binary_accuracy: 0.8372 - val_loss: 0.7447 - val_binary_accuracy: 0.7872\n",
      "Epoch 476/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3611 - binary_accuracy: 0.8512 - val_loss: 0.7647 - val_binary_accuracy: 0.7872\n",
      "Epoch 477/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3960 - binary_accuracy: 0.8372 - val_loss: 0.7590 - val_binary_accuracy: 0.7872\n",
      "Epoch 478/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3905 - binary_accuracy: 0.8419 - val_loss: 0.7709 - val_binary_accuracy: 0.7872\n",
      "Epoch 479/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4066 - binary_accuracy: 0.8558 - val_loss: 0.7862 - val_binary_accuracy: 0.7872\n",
      "Epoch 480/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4073 - binary_accuracy: 0.8465 - val_loss: 0.7817 - val_binary_accuracy: 0.7872\n",
      "Epoch 481/10000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4291 - binary_accuracy: 0.8512 - val_loss: 0.7586 - val_binary_accuracy: 0.7872\n",
      "Epoch 482/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3552 - binary_accuracy: 0.8651 - val_loss: 0.7494 - val_binary_accuracy: 0.7872\n",
      "Epoch 483/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4201 - binary_accuracy: 0.8512 - val_loss: 0.7667 - val_binary_accuracy: 0.7872\n",
      "Epoch 484/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3897 - binary_accuracy: 0.8744 - val_loss: 0.7732 - val_binary_accuracy: 0.7872\n",
      "Epoch 485/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4257 - binary_accuracy: 0.8326 - val_loss: 0.7805 - val_binary_accuracy: 0.7872\n",
      "Epoch 486/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3851 - binary_accuracy: 0.8605 - val_loss: 0.7772 - val_binary_accuracy: 0.7872\n",
      "Epoch 487/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4055 - binary_accuracy: 0.8512 - val_loss: 0.7511 - val_binary_accuracy: 0.7872\n",
      "Epoch 488/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4033 - binary_accuracy: 0.8419 - val_loss: 0.7432 - val_binary_accuracy: 0.7872\n",
      "Epoch 489/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3787 - binary_accuracy: 0.8558 - val_loss: 0.7413 - val_binary_accuracy: 0.7872\n",
      "Epoch 490/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3673 - binary_accuracy: 0.8651 - val_loss: 0.7390 - val_binary_accuracy: 0.7872\n",
      "Epoch 491/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3840 - binary_accuracy: 0.8512 - val_loss: 0.7488 - val_binary_accuracy: 0.7872\n",
      "Epoch 492/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4084 - binary_accuracy: 0.8558 - val_loss: 0.7412 - val_binary_accuracy: 0.7872\n",
      "Epoch 493/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4301 - binary_accuracy: 0.8372 - val_loss: 0.7190 - val_binary_accuracy: 0.7872\n",
      "Epoch 494/10000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.3855 - binary_accuracy: 0.8558 - val_loss: 0.7128 - val_binary_accuracy: 0.7872\n",
      "Epoch 495/10000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3937 - binary_accuracy: 0.8698 - val_loss: 0.7271 - val_binary_accuracy: 0.7872\n",
      "Epoch 496/10000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3984 - binary_accuracy: 0.8512 - val_loss: 0.7656 - val_binary_accuracy: 0.7872\n",
      "Epoch 497/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4429 - binary_accuracy: 0.8419 - val_loss: 0.7515 - val_binary_accuracy: 0.7872\n",
      "Epoch 498/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4523 - binary_accuracy: 0.8465 - val_loss: 0.7195 - val_binary_accuracy: 0.7872\n",
      "Epoch 499/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3880 - binary_accuracy: 0.8651 - val_loss: 0.7222 - val_binary_accuracy: 0.7872\n",
      "Epoch 500/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3814 - binary_accuracy: 0.8605 - val_loss: 0.7480 - val_binary_accuracy: 0.7872\n",
      "Epoch 501/10000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3918 - binary_accuracy: 0.8558 - val_loss: 0.7567 - val_binary_accuracy: 0.7872\n",
      "Epoch 502/10000\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.4009 - binary_accuracy: 0.8465 - val_loss: 0.7465 - val_binary_accuracy: 0.7872\n",
      "Epoch 503/10000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3814 - binary_accuracy: 0.8558 - val_loss: 0.7438 - val_binary_accuracy: 0.7872\n",
      "Epoch 504/10000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.4020 - binary_accuracy: 0.8419 - val_loss: 0.7519 - val_binary_accuracy: 0.7872\n",
      "Epoch 505/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4031 - binary_accuracy: 0.8558 - val_loss: 0.7492 - val_binary_accuracy: 0.7872\n",
      "Epoch 506/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3996 - binary_accuracy: 0.8558 - val_loss: 0.7635 - val_binary_accuracy: 0.7872\n",
      "Epoch 507/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3890 - binary_accuracy: 0.8651 - val_loss: 0.7289 - val_binary_accuracy: 0.7872\n",
      "Epoch 508/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3998 - binary_accuracy: 0.8465 - val_loss: 0.7369 - val_binary_accuracy: 0.7872\n",
      "Epoch 509/10000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.4320 - binary_accuracy: 0.8372 - val_loss: 0.7124 - val_binary_accuracy: 0.7872\n",
      "Epoch 510/10000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3936 - binary_accuracy: 0.8512 - val_loss: 0.7081 - val_binary_accuracy: 0.7872\n",
      "Epoch 511/10000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4009 - binary_accuracy: 0.8512 - val_loss: 0.7153 - val_binary_accuracy: 0.7872\n",
      "Epoch 512/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4214 - binary_accuracy: 0.8558 - val_loss: 0.7399 - val_binary_accuracy: 0.7872\n",
      "Epoch 513/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3973 - binary_accuracy: 0.8651 - val_loss: 0.7596 - val_binary_accuracy: 0.7872\n",
      "Epoch 514/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4155 - binary_accuracy: 0.8372 - val_loss: 0.7653 - val_binary_accuracy: 0.7872\n",
      "Epoch 515/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4315 - binary_accuracy: 0.8326 - val_loss: 0.7403 - val_binary_accuracy: 0.7872\n",
      "Epoch 516/10000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3821 - binary_accuracy: 0.8651 - val_loss: 0.7420 - val_binary_accuracy: 0.7872\n",
      "Epoch 517/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3905 - binary_accuracy: 0.8605 - val_loss: 0.7366 - val_binary_accuracy: 0.7872\n",
      "Epoch 518/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3858 - binary_accuracy: 0.8558 - val_loss: 0.7336 - val_binary_accuracy: 0.7872\n",
      "Epoch 519/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3943 - binary_accuracy: 0.8465 - val_loss: 0.7673 - val_binary_accuracy: 0.7872\n",
      "Epoch 520/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3800 - binary_accuracy: 0.8651 - val_loss: 0.7547 - val_binary_accuracy: 0.7872\n",
      "Epoch 521/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4104 - binary_accuracy: 0.8512 - val_loss: 0.7243 - val_binary_accuracy: 0.7872\n",
      "Epoch 522/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4094 - binary_accuracy: 0.8419 - val_loss: 0.7215 - val_binary_accuracy: 0.7872\n",
      "Epoch 523/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3752 - binary_accuracy: 0.8512 - val_loss: 0.7235 - val_binary_accuracy: 0.7872\n",
      "Epoch 524/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3866 - binary_accuracy: 0.8558 - val_loss: 0.7412 - val_binary_accuracy: 0.7872\n",
      "Epoch 525/10000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4089 - binary_accuracy: 0.8558 - val_loss: 0.7390 - val_binary_accuracy: 0.7872\n",
      "Epoch 526/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3804 - binary_accuracy: 0.8698 - val_loss: 0.7458 - val_binary_accuracy: 0.7872\n",
      "Epoch 527/10000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4003 - binary_accuracy: 0.8512 - val_loss: 0.7613 - val_binary_accuracy: 0.7872\n",
      "Epoch 528/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4103 - binary_accuracy: 0.8512 - val_loss: 0.7447 - val_binary_accuracy: 0.7872\n",
      "Epoch 529/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3793 - binary_accuracy: 0.8698 - val_loss: 0.7110 - val_binary_accuracy: 0.7872\n",
      "Epoch 530/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4095 - binary_accuracy: 0.8558 - val_loss: 0.7062 - val_binary_accuracy: 0.7872\n",
      "Epoch 531/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4113 - binary_accuracy: 0.8419 - val_loss: 0.7087 - val_binary_accuracy: 0.7872\n",
      "Epoch 532/10000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4003 - binary_accuracy: 0.8326 - val_loss: 0.7111 - val_binary_accuracy: 0.7872\n",
      "Epoch 533/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3814 - binary_accuracy: 0.8372 - val_loss: 0.7020 - val_binary_accuracy: 0.7872\n",
      "Epoch 534/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4123 - binary_accuracy: 0.8651 - val_loss: 0.7189 - val_binary_accuracy: 0.7872\n",
      "Epoch 535/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4128 - binary_accuracy: 0.8419 - val_loss: 0.7369 - val_binary_accuracy: 0.7872\n",
      "Epoch 536/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3697 - binary_accuracy: 0.8698 - val_loss: 0.7504 - val_binary_accuracy: 0.7872\n",
      "Epoch 537/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3813 - binary_accuracy: 0.8605 - val_loss: 0.7492 - val_binary_accuracy: 0.7872\n",
      "Epoch 538/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4102 - binary_accuracy: 0.8558 - val_loss: 0.7376 - val_binary_accuracy: 0.7872\n",
      "Epoch 539/10000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4148 - binary_accuracy: 0.8419 - val_loss: 0.7347 - val_binary_accuracy: 0.7872\n",
      "Epoch 540/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4060 - binary_accuracy: 0.8419 - val_loss: 0.7167 - val_binary_accuracy: 0.7872\n",
      "Epoch 541/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4381 - binary_accuracy: 0.8512 - val_loss: 0.7178 - val_binary_accuracy: 0.7872\n",
      "Epoch 542/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3759 - binary_accuracy: 0.8465 - val_loss: 0.7303 - val_binary_accuracy: 0.7872\n",
      "Epoch 543/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4112 - binary_accuracy: 0.8605 - val_loss: 0.7442 - val_binary_accuracy: 0.7872\n",
      "Epoch 544/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4060 - binary_accuracy: 0.8419 - val_loss: 0.7759 - val_binary_accuracy: 0.7872\n",
      "Epoch 545/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3850 - binary_accuracy: 0.8698 - val_loss: 0.8002 - val_binary_accuracy: 0.7872\n",
      "Epoch 546/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3728 - binary_accuracy: 0.8698 - val_loss: 0.8194 - val_binary_accuracy: 0.7872\n",
      "Epoch 547/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3942 - binary_accuracy: 0.8512 - val_loss: 0.8067 - val_binary_accuracy: 0.7872\n",
      "Epoch 548/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3982 - binary_accuracy: 0.8605 - val_loss: 0.7794 - val_binary_accuracy: 0.7872\n",
      "Epoch 549/10000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3837 - binary_accuracy: 0.8651 - val_loss: 0.7688 - val_binary_accuracy: 0.7872\n",
      "Epoch 550/10000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.4181 - binary_accuracy: 0.8186 - val_loss: 0.7544 - val_binary_accuracy: 0.7872\n",
      "Epoch 551/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3861 - binary_accuracy: 0.8558 - val_loss: 0.7319 - val_binary_accuracy: 0.7872\n",
      "Epoch 552/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4021 - binary_accuracy: 0.8419 - val_loss: 0.7490 - val_binary_accuracy: 0.7872\n",
      "Epoch 553/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3839 - binary_accuracy: 0.8465 - val_loss: 0.7706 - val_binary_accuracy: 0.7872\n",
      "Epoch 554/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3845 - binary_accuracy: 0.8419 - val_loss: 0.7563 - val_binary_accuracy: 0.7872\n",
      "Epoch 555/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4120 - binary_accuracy: 0.8372 - val_loss: 0.7677 - val_binary_accuracy: 0.7872\n",
      "Epoch 556/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3939 - binary_accuracy: 0.8465 - val_loss: 0.7492 - val_binary_accuracy: 0.7872\n",
      "Epoch 557/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4341 - binary_accuracy: 0.8465 - val_loss: 0.7241 - val_binary_accuracy: 0.7872\n",
      "Epoch 558/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3880 - binary_accuracy: 0.8558 - val_loss: 0.7166 - val_binary_accuracy: 0.7872\n",
      "Epoch 559/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3871 - binary_accuracy: 0.8698 - val_loss: 0.7390 - val_binary_accuracy: 0.7872\n",
      "Epoch 560/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3914 - binary_accuracy: 0.8651 - val_loss: 0.7474 - val_binary_accuracy: 0.7872\n",
      "Epoch 561/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3982 - binary_accuracy: 0.8512 - val_loss: 0.7758 - val_binary_accuracy: 0.7872\n",
      "Epoch 562/10000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3945 - binary_accuracy: 0.8419 - val_loss: 0.7590 - val_binary_accuracy: 0.7872\n",
      "Epoch 563/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3947 - binary_accuracy: 0.8605 - val_loss: 0.7368 - val_binary_accuracy: 0.7872\n",
      "Epoch 564/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4011 - binary_accuracy: 0.8465 - val_loss: 0.7449 - val_binary_accuracy: 0.7872\n",
      "Epoch 565/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4186 - binary_accuracy: 0.8512 - val_loss: 0.7403 - val_binary_accuracy: 0.7872\n",
      "Epoch 566/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4282 - binary_accuracy: 0.8419 - val_loss: 0.7131 - val_binary_accuracy: 0.7872\n",
      "Epoch 567/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4076 - binary_accuracy: 0.8605 - val_loss: 0.7008 - val_binary_accuracy: 0.7872\n",
      "Epoch 568/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3921 - binary_accuracy: 0.8465 - val_loss: 0.7058 - val_binary_accuracy: 0.7872\n",
      "Epoch 569/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4400 - binary_accuracy: 0.8279 - val_loss: 0.7040 - val_binary_accuracy: 0.7872\n",
      "Epoch 570/10000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3835 - binary_accuracy: 0.8558 - val_loss: 0.7119 - val_binary_accuracy: 0.7872\n",
      "Epoch 571/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4290 - binary_accuracy: 0.8512 - val_loss: 0.7175 - val_binary_accuracy: 0.7872\n",
      "Epoch 572/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4409 - binary_accuracy: 0.8419 - val_loss: 0.7166 - val_binary_accuracy: 0.7872\n",
      "Epoch 573/10000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3920 - binary_accuracy: 0.8605 - val_loss: 0.7245 - val_binary_accuracy: 0.7872\n",
      "Epoch 574/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3999 - binary_accuracy: 0.8744 - val_loss: 0.7544 - val_binary_accuracy: 0.7872\n",
      "Epoch 575/10000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4308 - binary_accuracy: 0.8419 - val_loss: 0.7710 - val_binary_accuracy: 0.7872\n",
      "Epoch 576/10000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3975 - binary_accuracy: 0.8558 - val_loss: 0.7607 - val_binary_accuracy: 0.7872\n",
      "Epoch 577/10000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4439 - binary_accuracy: 0.8512 - val_loss: 0.7346 - val_binary_accuracy: 0.7872\n",
      "Epoch 578/10000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4440 - binary_accuracy: 0.8326 - val_loss: 0.7150 - val_binary_accuracy: 0.7872\n",
      "Epoch 579/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4182 - binary_accuracy: 0.8512 - val_loss: 0.7041 - val_binary_accuracy: 0.7872\n",
      "Epoch 580/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3894 - binary_accuracy: 0.8558 - val_loss: 0.7119 - val_binary_accuracy: 0.7872\n",
      "Epoch 581/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4069 - binary_accuracy: 0.8512 - val_loss: 0.7301 - val_binary_accuracy: 0.7872\n",
      "Epoch 582/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4199 - binary_accuracy: 0.8558 - val_loss: 0.7224 - val_binary_accuracy: 0.7872\n",
      "Epoch 583/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3665 - binary_accuracy: 0.8558 - val_loss: 0.7391 - val_binary_accuracy: 0.7872\n",
      "Epoch 584/10000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.3859 - binary_accuracy: 0.8512 - val_loss: 0.7650 - val_binary_accuracy: 0.7872\n",
      "Epoch 585/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3567 - binary_accuracy: 0.8558 - val_loss: 0.7737 - val_binary_accuracy: 0.7872\n",
      "Epoch 586/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4210 - binary_accuracy: 0.8651 - val_loss: 0.7530 - val_binary_accuracy: 0.7872\n",
      "Epoch 587/10000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4111 - binary_accuracy: 0.8419 - val_loss: 0.7452 - val_binary_accuracy: 0.7872\n",
      "Epoch 588/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4020 - binary_accuracy: 0.8558 - val_loss: 0.7253 - val_binary_accuracy: 0.7872\n",
      "Epoch 589/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3891 - binary_accuracy: 0.8744 - val_loss: 0.7279 - val_binary_accuracy: 0.7872\n",
      "Epoch 590/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3521 - binary_accuracy: 0.8884 - val_loss: 0.7496 - val_binary_accuracy: 0.7872\n",
      "Epoch 591/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4312 - binary_accuracy: 0.8465 - val_loss: 0.7733 - val_binary_accuracy: 0.7872\n",
      "Epoch 592/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3867 - binary_accuracy: 0.8651 - val_loss: 0.7684 - val_binary_accuracy: 0.7872\n",
      "Epoch 593/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4238 - binary_accuracy: 0.8419 - val_loss: 0.7551 - val_binary_accuracy: 0.7872\n",
      "Epoch 594/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3912 - binary_accuracy: 0.8465 - val_loss: 0.7518 - val_binary_accuracy: 0.7872\n",
      "Epoch 595/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3897 - binary_accuracy: 0.8419 - val_loss: 0.7486 - val_binary_accuracy: 0.7872\n",
      "Epoch 596/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3749 - binary_accuracy: 0.8651 - val_loss: 0.7384 - val_binary_accuracy: 0.7872\n",
      "Epoch 597/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3769 - binary_accuracy: 0.8465 - val_loss: 0.7507 - val_binary_accuracy: 0.7872\n",
      "Epoch 598/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3893 - binary_accuracy: 0.8558 - val_loss: 0.7567 - val_binary_accuracy: 0.7872\n",
      "Epoch 599/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4173 - binary_accuracy: 0.8791 - val_loss: 0.7519 - val_binary_accuracy: 0.7872\n",
      "Epoch 600/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3987 - binary_accuracy: 0.8512 - val_loss: 0.7394 - val_binary_accuracy: 0.7872\n",
      "Epoch 601/10000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4025 - binary_accuracy: 0.8698 - val_loss: 0.7519 - val_binary_accuracy: 0.7872\n",
      "Epoch 602/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3978 - binary_accuracy: 0.8651 - val_loss: 0.7479 - val_binary_accuracy: 0.7872\n",
      "Epoch 603/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4078 - binary_accuracy: 0.8372 - val_loss: 0.7330 - val_binary_accuracy: 0.7872\n",
      "Epoch 604/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4047 - binary_accuracy: 0.8651 - val_loss: 0.7226 - val_binary_accuracy: 0.7872\n",
      "Epoch 605/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4009 - binary_accuracy: 0.8419 - val_loss: 0.7437 - val_binary_accuracy: 0.7872\n",
      "Epoch 606/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4117 - binary_accuracy: 0.8558 - val_loss: 0.7761 - val_binary_accuracy: 0.7872\n",
      "Epoch 607/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4266 - binary_accuracy: 0.8465 - val_loss: 0.7872 - val_binary_accuracy: 0.7872\n",
      "Epoch 608/10000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4067 - binary_accuracy: 0.8512 - val_loss: 0.7577 - val_binary_accuracy: 0.7872\n",
      "Epoch 609/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3973 - binary_accuracy: 0.8512 - val_loss: 0.7441 - val_binary_accuracy: 0.7872\n",
      "Epoch 610/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3942 - binary_accuracy: 0.8372 - val_loss: 0.7532 - val_binary_accuracy: 0.7872\n",
      "Epoch 611/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4131 - binary_accuracy: 0.8419 - val_loss: 0.7570 - val_binary_accuracy: 0.7872\n",
      "Epoch 612/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4224 - binary_accuracy: 0.8279 - val_loss: 0.7670 - val_binary_accuracy: 0.7872\n",
      "Epoch 613/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4231 - binary_accuracy: 0.8558 - val_loss: 0.7481 - val_binary_accuracy: 0.7872\n",
      "Epoch 614/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4013 - binary_accuracy: 0.8372 - val_loss: 0.7306 - val_binary_accuracy: 0.7872\n",
      "Epoch 615/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4041 - binary_accuracy: 0.8512 - val_loss: 0.7266 - val_binary_accuracy: 0.7872\n",
      "Epoch 616/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3962 - binary_accuracy: 0.8512 - val_loss: 0.7022 - val_binary_accuracy: 0.7872\n",
      "Epoch 617/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3825 - binary_accuracy: 0.8698 - val_loss: 0.7189 - val_binary_accuracy: 0.7872\n",
      "Epoch 618/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3994 - binary_accuracy: 0.8605 - val_loss: 0.7371 - val_binary_accuracy: 0.7872\n",
      "Epoch 619/10000\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3888 - binary_accuracy: 0.8605 - val_loss: 0.7344 - val_binary_accuracy: 0.7872\n",
      "Epoch 620/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3883 - binary_accuracy: 0.8698 - val_loss: 0.7721 - val_binary_accuracy: 0.7872\n",
      "Epoch 621/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3885 - binary_accuracy: 0.8651 - val_loss: 0.7771 - val_binary_accuracy: 0.7872\n",
      "Epoch 622/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3771 - binary_accuracy: 0.8605 - val_loss: 0.7787 - val_binary_accuracy: 0.7872\n",
      "Epoch 623/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3651 - binary_accuracy: 0.8651 - val_loss: 0.7600 - val_binary_accuracy: 0.7872\n",
      "Epoch 624/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3828 - binary_accuracy: 0.8465 - val_loss: 0.7415 - val_binary_accuracy: 0.7872\n",
      "Epoch 625/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3959 - binary_accuracy: 0.8605 - val_loss: 0.7401 - val_binary_accuracy: 0.7872\n",
      "Epoch 626/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3933 - binary_accuracy: 0.8698 - val_loss: 0.7384 - val_binary_accuracy: 0.7872\n",
      "Epoch 627/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4076 - binary_accuracy: 0.8419 - val_loss: 0.7341 - val_binary_accuracy: 0.7872\n",
      "Epoch 628/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4083 - binary_accuracy: 0.8558 - val_loss: 0.7355 - val_binary_accuracy: 0.7872\n",
      "Epoch 629/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3907 - binary_accuracy: 0.8698 - val_loss: 0.7442 - val_binary_accuracy: 0.7872\n",
      "Epoch 630/10000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3642 - binary_accuracy: 0.8605 - val_loss: 0.7515 - val_binary_accuracy: 0.7872\n",
      "Epoch 631/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4120 - binary_accuracy: 0.8465 - val_loss: 0.7559 - val_binary_accuracy: 0.7872\n",
      "Epoch 632/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3930 - binary_accuracy: 0.8558 - val_loss: 0.7681 - val_binary_accuracy: 0.7872\n",
      "Epoch 633/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3681 - binary_accuracy: 0.8605 - val_loss: 0.7701 - val_binary_accuracy: 0.7872\n",
      "Epoch 634/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3919 - binary_accuracy: 0.8465 - val_loss: 0.7878 - val_binary_accuracy: 0.7872\n",
      "Epoch 635/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3997 - binary_accuracy: 0.8558 - val_loss: 0.7674 - val_binary_accuracy: 0.7872\n",
      "Epoch 636/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3811 - binary_accuracy: 0.8512 - val_loss: 0.7791 - val_binary_accuracy: 0.7872\n",
      "Epoch 637/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3532 - binary_accuracy: 0.8605 - val_loss: 0.7724 - val_binary_accuracy: 0.7872\n",
      "Epoch 638/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3780 - binary_accuracy: 0.8698 - val_loss: 0.7825 - val_binary_accuracy: 0.7872\n",
      "Epoch 639/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4134 - binary_accuracy: 0.8419 - val_loss: 0.7646 - val_binary_accuracy: 0.7872\n",
      "Epoch 640/10000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3971 - binary_accuracy: 0.8558 - val_loss: 0.7217 - val_binary_accuracy: 0.7872\n",
      "Epoch 641/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3650 - binary_accuracy: 0.8698 - val_loss: 0.7113 - val_binary_accuracy: 0.7872\n",
      "Epoch 642/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3768 - binary_accuracy: 0.8558 - val_loss: 0.7306 - val_binary_accuracy: 0.7872\n",
      "Epoch 643/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4167 - binary_accuracy: 0.8279 - val_loss: 0.7482 - val_binary_accuracy: 0.7872\n",
      "Epoch 644/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4048 - binary_accuracy: 0.8558 - val_loss: 0.7488 - val_binary_accuracy: 0.7872\n",
      "Epoch 645/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3933 - binary_accuracy: 0.8605 - val_loss: 0.7512 - val_binary_accuracy: 0.7872\n",
      "Epoch 646/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3969 - binary_accuracy: 0.8512 - val_loss: 0.7675 - val_binary_accuracy: 0.7872\n",
      "Epoch 647/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3946 - binary_accuracy: 0.8465 - val_loss: 0.7777 - val_binary_accuracy: 0.7872\n",
      "Epoch 648/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4004 - binary_accuracy: 0.8512 - val_loss: 0.7673 - val_binary_accuracy: 0.7872\n",
      "Epoch 649/10000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3812 - binary_accuracy: 0.8512 - val_loss: 0.7782 - val_binary_accuracy: 0.7872\n",
      "Epoch 650/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4144 - binary_accuracy: 0.8465 - val_loss: 0.7763 - val_binary_accuracy: 0.7872\n",
      "Epoch 651/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3951 - binary_accuracy: 0.8605 - val_loss: 0.7698 - val_binary_accuracy: 0.7872\n",
      "Epoch 652/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3949 - binary_accuracy: 0.8419 - val_loss: 0.7777 - val_binary_accuracy: 0.7872\n",
      "Epoch 653/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4106 - binary_accuracy: 0.8419 - val_loss: 0.7864 - val_binary_accuracy: 0.7872\n",
      "Epoch 654/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3787 - binary_accuracy: 0.8605 - val_loss: 0.7808 - val_binary_accuracy: 0.7872\n",
      "Epoch 655/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3643 - binary_accuracy: 0.8744 - val_loss: 0.8058 - val_binary_accuracy: 0.7872\n",
      "Epoch 656/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4145 - binary_accuracy: 0.8419 - val_loss: 0.8173 - val_binary_accuracy: 0.7872\n",
      "Epoch 657/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4061 - binary_accuracy: 0.8512 - val_loss: 0.7825 - val_binary_accuracy: 0.7872\n",
      "Epoch 658/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4213 - binary_accuracy: 0.8465 - val_loss: 0.7529 - val_binary_accuracy: 0.7872\n",
      "Epoch 659/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3879 - binary_accuracy: 0.8605 - val_loss: 0.7350 - val_binary_accuracy: 0.7872\n",
      "Epoch 660/10000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4106 - binary_accuracy: 0.8512 - val_loss: 0.7415 - val_binary_accuracy: 0.7872\n",
      "Epoch 661/10000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3703 - binary_accuracy: 0.8558 - val_loss: 0.7484 - val_binary_accuracy: 0.7872\n",
      "Epoch 662/10000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3865 - binary_accuracy: 0.8419 - val_loss: 0.7656 - val_binary_accuracy: 0.7872\n",
      "Epoch 663/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3950 - binary_accuracy: 0.8651 - val_loss: 0.7621 - val_binary_accuracy: 0.7872\n",
      "Epoch 664/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3913 - binary_accuracy: 0.8651 - val_loss: 0.7604 - val_binary_accuracy: 0.7872\n",
      "Epoch 665/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4060 - binary_accuracy: 0.8651 - val_loss: 0.7570 - val_binary_accuracy: 0.7872\n",
      "Epoch 666/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3759 - binary_accuracy: 0.8512 - val_loss: 0.7441 - val_binary_accuracy: 0.7872\n",
      "Epoch 667/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3664 - binary_accuracy: 0.8558 - val_loss: 0.7177 - val_binary_accuracy: 0.7872\n",
      "Epoch 668/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4056 - binary_accuracy: 0.8326 - val_loss: 0.7317 - val_binary_accuracy: 0.7872\n",
      "Epoch 669/10000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3976 - binary_accuracy: 0.8512 - val_loss: 0.7378 - val_binary_accuracy: 0.7872\n",
      "Epoch 670/10000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3690 - binary_accuracy: 0.8698 - val_loss: 0.7631 - val_binary_accuracy: 0.7872\n",
      "Epoch 671/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4204 - binary_accuracy: 0.8465 - val_loss: 0.7548 - val_binary_accuracy: 0.7872\n",
      "Epoch 672/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4104 - binary_accuracy: 0.8605 - val_loss: 0.7266 - val_binary_accuracy: 0.7872\n",
      "Epoch 673/10000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4157 - binary_accuracy: 0.8419 - val_loss: 0.7086 - val_binary_accuracy: 0.7872\n",
      "Epoch 674/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3799 - binary_accuracy: 0.8605 - val_loss: 0.7330 - val_binary_accuracy: 0.7872\n",
      "Epoch 675/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4005 - binary_accuracy: 0.8279 - val_loss: 0.7801 - val_binary_accuracy: 0.7872\n",
      "Epoch 676/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3974 - binary_accuracy: 0.8558 - val_loss: 0.7947 - val_binary_accuracy: 0.7872\n",
      "Epoch 677/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4091 - binary_accuracy: 0.8372 - val_loss: 0.7763 - val_binary_accuracy: 0.7872\n",
      "Epoch 678/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4008 - binary_accuracy: 0.8558 - val_loss: 0.7660 - val_binary_accuracy: 0.7872\n",
      "Epoch 679/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3935 - binary_accuracy: 0.8558 - val_loss: 0.7470 - val_binary_accuracy: 0.7872\n",
      "Epoch 680/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4072 - binary_accuracy: 0.8558 - val_loss: 0.7445 - val_binary_accuracy: 0.7872\n",
      "Epoch 681/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3870 - binary_accuracy: 0.8698 - val_loss: 0.7701 - val_binary_accuracy: 0.7872\n",
      "Epoch 682/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3963 - binary_accuracy: 0.8372 - val_loss: 0.7555 - val_binary_accuracy: 0.7872\n",
      "Epoch 683/10000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3969 - binary_accuracy: 0.8605 - val_loss: 0.7500 - val_binary_accuracy: 0.7872\n",
      "Epoch 684/10000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4044 - binary_accuracy: 0.8512 - val_loss: 0.7687 - val_binary_accuracy: 0.7872\n",
      "Epoch 685/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3622 - binary_accuracy: 0.8698 - val_loss: 0.7629 - val_binary_accuracy: 0.7872\n",
      "Epoch 686/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4055 - binary_accuracy: 0.8558 - val_loss: 0.7577 - val_binary_accuracy: 0.7872\n",
      "Epoch 687/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3882 - binary_accuracy: 0.8651 - val_loss: 0.7492 - val_binary_accuracy: 0.7872\n",
      "Epoch 688/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4119 - binary_accuracy: 0.8465 - val_loss: 0.7188 - val_binary_accuracy: 0.7872\n",
      "Epoch 689/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4034 - binary_accuracy: 0.8419 - val_loss: 0.6919 - val_binary_accuracy: 0.7872\n",
      "Epoch 690/10000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4259 - binary_accuracy: 0.8512 - val_loss: 0.6862 - val_binary_accuracy: 0.7872\n",
      "Epoch 691/10000\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.4036 - binary_accuracy: 0.8419 - val_loss: 0.6906 - val_binary_accuracy: 0.7872\n",
      "Epoch 692/10000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3991 - binary_accuracy: 0.8605 - val_loss: 0.7030 - val_binary_accuracy: 0.7872\n",
      "Epoch 693/10000\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.3700 - binary_accuracy: 0.8791 - val_loss: 0.7154 - val_binary_accuracy: 0.7872\n",
      "Epoch 694/10000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.4286 - binary_accuracy: 0.8558 - val_loss: 0.7158 - val_binary_accuracy: 0.7872\n",
      "Epoch 695/10000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3865 - binary_accuracy: 0.8698 - val_loss: 0.7346 - val_binary_accuracy: 0.7872\n",
      "Epoch 696/10000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3953 - binary_accuracy: 0.8465 - val_loss: 0.7278 - val_binary_accuracy: 0.7872\n",
      "Epoch 697/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4023 - binary_accuracy: 0.8698 - val_loss: 0.7283 - val_binary_accuracy: 0.7872\n",
      "Epoch 698/10000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3750 - binary_accuracy: 0.8558 - val_loss: 0.7307 - val_binary_accuracy: 0.7872\n",
      "Epoch 699/10000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4391 - binary_accuracy: 0.8279 - val_loss: 0.7146 - val_binary_accuracy: 0.7872\n",
      "Epoch 700/10000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3780 - binary_accuracy: 0.8698 - val_loss: 0.7316 - val_binary_accuracy: 0.7872\n",
      "Epoch 701/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4230 - binary_accuracy: 0.8326 - val_loss: 0.7347 - val_binary_accuracy: 0.7872\n",
      "Epoch 702/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4007 - binary_accuracy: 0.8698 - val_loss: 0.7471 - val_binary_accuracy: 0.7872\n",
      "Epoch 703/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3979 - binary_accuracy: 0.8512 - val_loss: 0.7583 - val_binary_accuracy: 0.7872\n",
      "Epoch 704/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4091 - binary_accuracy: 0.8279 - val_loss: 0.7580 - val_binary_accuracy: 0.7872\n",
      "Epoch 705/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4148 - binary_accuracy: 0.8512 - val_loss: 0.7488 - val_binary_accuracy: 0.7872\n",
      "Epoch 706/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4145 - binary_accuracy: 0.8372 - val_loss: 0.7360 - val_binary_accuracy: 0.7872\n",
      "Epoch 707/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4142 - binary_accuracy: 0.8512 - val_loss: 0.7416 - val_binary_accuracy: 0.7872\n",
      "Epoch 708/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4117 - binary_accuracy: 0.8651 - val_loss: 0.7533 - val_binary_accuracy: 0.7872\n",
      "Epoch 709/10000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4253 - binary_accuracy: 0.8279 - val_loss: 0.7453 - val_binary_accuracy: 0.7872\n",
      "Epoch 710/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4131 - binary_accuracy: 0.8698 - val_loss: 0.7312 - val_binary_accuracy: 0.7872\n",
      "Epoch 711/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4209 - binary_accuracy: 0.8326 - val_loss: 0.7428 - val_binary_accuracy: 0.7872\n",
      "Epoch 712/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4052 - binary_accuracy: 0.8465 - val_loss: 0.7631 - val_binary_accuracy: 0.7872\n",
      "Epoch 713/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4060 - binary_accuracy: 0.8651 - val_loss: 0.7918 - val_binary_accuracy: 0.7872\n",
      "Epoch 714/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4500 - binary_accuracy: 0.8419 - val_loss: 0.7868 - val_binary_accuracy: 0.7872\n",
      "Epoch 715/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3938 - binary_accuracy: 0.8605 - val_loss: 0.7817 - val_binary_accuracy: 0.7872\n",
      "Epoch 716/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3987 - binary_accuracy: 0.8744 - val_loss: 0.7680 - val_binary_accuracy: 0.7872\n",
      "Epoch 717/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4189 - binary_accuracy: 0.8512 - val_loss: 0.7515 - val_binary_accuracy: 0.7872\n",
      "Epoch 718/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3827 - binary_accuracy: 0.8558 - val_loss: 0.7513 - val_binary_accuracy: 0.7872\n",
      "Epoch 719/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3981 - binary_accuracy: 0.8558 - val_loss: 0.7504 - val_binary_accuracy: 0.7872\n",
      "Epoch 720/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3904 - binary_accuracy: 0.8465 - val_loss: 0.7360 - val_binary_accuracy: 0.7872\n",
      "Epoch 721/10000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4256 - binary_accuracy: 0.8372 - val_loss: 0.7423 - val_binary_accuracy: 0.7872\n",
      "Epoch 722/10000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4031 - binary_accuracy: 0.8326 - val_loss: 0.7569 - val_binary_accuracy: 0.7872\n",
      "Epoch 723/10000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.4444 - binary_accuracy: 0.8093 - val_loss: 0.7427 - val_binary_accuracy: 0.7872\n",
      "Epoch 724/10000\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3971 - binary_accuracy: 0.8558 - val_loss: 0.7115 - val_binary_accuracy: 0.7872\n",
      "Epoch 725/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4145 - binary_accuracy: 0.8372 - val_loss: 0.7081 - val_binary_accuracy: 0.7872\n",
      "Epoch 726/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4067 - binary_accuracy: 0.8419 - val_loss: 0.7073 - val_binary_accuracy: 0.7872\n",
      "Epoch 727/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3942 - binary_accuracy: 0.8698 - val_loss: 0.7146 - val_binary_accuracy: 0.7872\n",
      "Epoch 728/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3862 - binary_accuracy: 0.8651 - val_loss: 0.7198 - val_binary_accuracy: 0.7872\n",
      "Epoch 729/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3957 - binary_accuracy: 0.8558 - val_loss: 0.7477 - val_binary_accuracy: 0.7872\n",
      "Epoch 730/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3817 - binary_accuracy: 0.8558 - val_loss: 0.7654 - val_binary_accuracy: 0.7872\n",
      "Epoch 731/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3823 - binary_accuracy: 0.8558 - val_loss: 0.7673 - val_binary_accuracy: 0.7872\n",
      "Epoch 732/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3796 - binary_accuracy: 0.8884 - val_loss: 0.7557 - val_binary_accuracy: 0.7872\n",
      "Epoch 733/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3860 - binary_accuracy: 0.8698 - val_loss: 0.7504 - val_binary_accuracy: 0.7872\n",
      "Epoch 734/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4183 - binary_accuracy: 0.8605 - val_loss: 0.7543 - val_binary_accuracy: 0.7872\n",
      "Epoch 735/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3658 - binary_accuracy: 0.8791 - val_loss: 0.7422 - val_binary_accuracy: 0.7872\n",
      "Epoch 736/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4085 - binary_accuracy: 0.8558 - val_loss: 0.7251 - val_binary_accuracy: 0.7872\n",
      "Epoch 737/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3857 - binary_accuracy: 0.8651 - val_loss: 0.6958 - val_binary_accuracy: 0.7872\n",
      "Epoch 738/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3994 - binary_accuracy: 0.8744 - val_loss: 0.6935 - val_binary_accuracy: 0.7872\n",
      "Epoch 739/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3847 - binary_accuracy: 0.8698 - val_loss: 0.7256 - val_binary_accuracy: 0.7872\n",
      "Epoch 740/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3695 - binary_accuracy: 0.8558 - val_loss: 0.7593 - val_binary_accuracy: 0.7872\n",
      "Epoch 741/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3871 - binary_accuracy: 0.8698 - val_loss: 0.7500 - val_binary_accuracy: 0.7872\n",
      "Epoch 742/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3738 - binary_accuracy: 0.8558 - val_loss: 0.7264 - val_binary_accuracy: 0.7872\n",
      "Epoch 743/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4045 - binary_accuracy: 0.8419 - val_loss: 0.7534 - val_binary_accuracy: 0.7872\n",
      "Epoch 744/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4041 - binary_accuracy: 0.8372 - val_loss: 0.7346 - val_binary_accuracy: 0.7872\n",
      "Epoch 745/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3987 - binary_accuracy: 0.8419 - val_loss: 0.7282 - val_binary_accuracy: 0.7872\n",
      "Epoch 746/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3903 - binary_accuracy: 0.8558 - val_loss: 0.7376 - val_binary_accuracy: 0.7872\n",
      "Epoch 747/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4185 - binary_accuracy: 0.8465 - val_loss: 0.7329 - val_binary_accuracy: 0.7872\n",
      "Epoch 748/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3923 - binary_accuracy: 0.8512 - val_loss: 0.7095 - val_binary_accuracy: 0.7872\n",
      "Epoch 749/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3999 - binary_accuracy: 0.8512 - val_loss: 0.7211 - val_binary_accuracy: 0.7872\n",
      "Epoch 750/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3933 - binary_accuracy: 0.8558 - val_loss: 0.7415 - val_binary_accuracy: 0.7872\n",
      "Epoch 751/10000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3887 - binary_accuracy: 0.8651 - val_loss: 0.7549 - val_binary_accuracy: 0.7872\n",
      "Epoch 752/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3967 - binary_accuracy: 0.8465 - val_loss: 0.7467 - val_binary_accuracy: 0.7872\n",
      "Epoch 753/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4212 - binary_accuracy: 0.8419 - val_loss: 0.7417 - val_binary_accuracy: 0.7872\n",
      "Epoch 754/10000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3723 - binary_accuracy: 0.8558 - val_loss: 0.7408 - val_binary_accuracy: 0.7872\n",
      "Epoch 755/10000\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.3646 - binary_accuracy: 0.8651 - val_loss: 0.7475 - val_binary_accuracy: 0.7872\n",
      "Epoch 756/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3969 - binary_accuracy: 0.8558 - val_loss: 0.7382 - val_binary_accuracy: 0.7660\n",
      "Epoch 757/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3900 - binary_accuracy: 0.8651 - val_loss: 0.7637 - val_binary_accuracy: 0.7872\n",
      "Epoch 758/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3874 - binary_accuracy: 0.8558 - val_loss: 0.7697 - val_binary_accuracy: 0.7872\n",
      "Epoch 759/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4077 - binary_accuracy: 0.8651 - val_loss: 0.7542 - val_binary_accuracy: 0.7872\n",
      "Epoch 760/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3846 - binary_accuracy: 0.8605 - val_loss: 0.7340 - val_binary_accuracy: 0.7872\n",
      "Epoch 761/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4075 - binary_accuracy: 0.8233 - val_loss: 0.7375 - val_binary_accuracy: 0.7872\n",
      "Epoch 762/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4019 - binary_accuracy: 0.8279 - val_loss: 0.7564 - val_binary_accuracy: 0.7872\n",
      "Epoch 763/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3895 - binary_accuracy: 0.8698 - val_loss: 0.7736 - val_binary_accuracy: 0.7872\n",
      "Epoch 764/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4254 - binary_accuracy: 0.8605 - val_loss: 0.7440 - val_binary_accuracy: 0.7872\n",
      "Epoch 765/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4182 - binary_accuracy: 0.8512 - val_loss: 0.7290 - val_binary_accuracy: 0.7872\n",
      "Epoch 766/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4025 - binary_accuracy: 0.8605 - val_loss: 0.7223 - val_binary_accuracy: 0.7872\n",
      "Epoch 767/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4139 - binary_accuracy: 0.8465 - val_loss: 0.7164 - val_binary_accuracy: 0.7872\n",
      "Epoch 768/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3688 - binary_accuracy: 0.8698 - val_loss: 0.7222 - val_binary_accuracy: 0.7872\n",
      "Epoch 769/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3913 - binary_accuracy: 0.8512 - val_loss: 0.7385 - val_binary_accuracy: 0.7872\n",
      "Epoch 770/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4131 - binary_accuracy: 0.8791 - val_loss: 0.7198 - val_binary_accuracy: 0.7872\n",
      "Epoch 771/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3988 - binary_accuracy: 0.8605 - val_loss: 0.7132 - val_binary_accuracy: 0.7872\n",
      "Epoch 772/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4318 - binary_accuracy: 0.8372 - val_loss: 0.7217 - val_binary_accuracy: 0.7872\n",
      "Epoch 773/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4056 - binary_accuracy: 0.8465 - val_loss: 0.7375 - val_binary_accuracy: 0.7872\n",
      "Epoch 774/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3895 - binary_accuracy: 0.8605 - val_loss: 0.7288 - val_binary_accuracy: 0.7872\n",
      "Epoch 775/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4380 - binary_accuracy: 0.8512 - val_loss: 0.7243 - val_binary_accuracy: 0.7872\n",
      "Epoch 776/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4124 - binary_accuracy: 0.8605 - val_loss: 0.7181 - val_binary_accuracy: 0.7872\n",
      "Epoch 777/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3972 - binary_accuracy: 0.8651 - val_loss: 0.7227 - val_binary_accuracy: 0.7872\n",
      "Epoch 778/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3904 - binary_accuracy: 0.8419 - val_loss: 0.7149 - val_binary_accuracy: 0.7872\n",
      "Epoch 779/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3625 - binary_accuracy: 0.8698 - val_loss: 0.7170 - val_binary_accuracy: 0.7872\n",
      "Epoch 780/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4398 - binary_accuracy: 0.8047 - val_loss: 0.7010 - val_binary_accuracy: 0.7872\n",
      "Epoch 781/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3773 - binary_accuracy: 0.8651 - val_loss: 0.7092 - val_binary_accuracy: 0.7872\n",
      "Epoch 782/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4173 - binary_accuracy: 0.8512 - val_loss: 0.6987 - val_binary_accuracy: 0.7872\n",
      "Epoch 783/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3780 - binary_accuracy: 0.8512 - val_loss: 0.7204 - val_binary_accuracy: 0.7872\n",
      "Epoch 784/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3814 - binary_accuracy: 0.8558 - val_loss: 0.7115 - val_binary_accuracy: 0.7872\n",
      "Epoch 785/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4136 - binary_accuracy: 0.8465 - val_loss: 0.7156 - val_binary_accuracy: 0.7872\n",
      "Epoch 786/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4001 - binary_accuracy: 0.8558 - val_loss: 0.7140 - val_binary_accuracy: 0.7872\n",
      "Epoch 787/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4068 - binary_accuracy: 0.8512 - val_loss: 0.7261 - val_binary_accuracy: 0.7872\n",
      "Epoch 788/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4016 - binary_accuracy: 0.8465 - val_loss: 0.7333 - val_binary_accuracy: 0.7872\n",
      "Epoch 789/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4114 - binary_accuracy: 0.8605 - val_loss: 0.7193 - val_binary_accuracy: 0.7872\n",
      "Epoch 790/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4094 - binary_accuracy: 0.8605 - val_loss: 0.7387 - val_binary_accuracy: 0.7872\n",
      "Epoch 791/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3900 - binary_accuracy: 0.8651 - val_loss: 0.7364 - val_binary_accuracy: 0.7872\n",
      "Epoch 792/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3818 - binary_accuracy: 0.8512 - val_loss: 0.7272 - val_binary_accuracy: 0.7872\n",
      "Epoch 793/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3837 - binary_accuracy: 0.8419 - val_loss: 0.7313 - val_binary_accuracy: 0.7872\n",
      "Epoch 794/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4160 - binary_accuracy: 0.8372 - val_loss: 0.7428 - val_binary_accuracy: 0.7872\n",
      "Epoch 795/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3850 - binary_accuracy: 0.8558 - val_loss: 0.7287 - val_binary_accuracy: 0.7872\n",
      "Epoch 796/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3936 - binary_accuracy: 0.8558 - val_loss: 0.7247 - val_binary_accuracy: 0.7872\n",
      "Epoch 797/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4047 - binary_accuracy: 0.8651 - val_loss: 0.7267 - val_binary_accuracy: 0.7872\n",
      "Epoch 798/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4117 - binary_accuracy: 0.8558 - val_loss: 0.7022 - val_binary_accuracy: 0.7872\n",
      "Epoch 799/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3744 - binary_accuracy: 0.8698 - val_loss: 0.6890 - val_binary_accuracy: 0.7872\n",
      "Epoch 800/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4346 - binary_accuracy: 0.8465 - val_loss: 0.7098 - val_binary_accuracy: 0.7872\n",
      "Epoch 801/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4172 - binary_accuracy: 0.8558 - val_loss: 0.7166 - val_binary_accuracy: 0.7872\n",
      "Epoch 802/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4039 - binary_accuracy: 0.8558 - val_loss: 0.6979 - val_binary_accuracy: 0.7872\n",
      "Epoch 803/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4130 - binary_accuracy: 0.8558 - val_loss: 0.6865 - val_binary_accuracy: 0.7872\n",
      "Epoch 804/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4057 - binary_accuracy: 0.8512 - val_loss: 0.7042 - val_binary_accuracy: 0.7872\n",
      "Epoch 805/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4048 - binary_accuracy: 0.8326 - val_loss: 0.7176 - val_binary_accuracy: 0.7872\n",
      "Epoch 806/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3809 - binary_accuracy: 0.8419 - val_loss: 0.7451 - val_binary_accuracy: 0.7872\n",
      "Epoch 807/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3866 - binary_accuracy: 0.8698 - val_loss: 0.7570 - val_binary_accuracy: 0.7872\n",
      "Epoch 808/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4093 - binary_accuracy: 0.8605 - val_loss: 0.7529 - val_binary_accuracy: 0.7872\n",
      "Epoch 809/10000\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3697 - binary_accuracy: 0.8558 - val_loss: 0.7572 - val_binary_accuracy: 0.7872\n",
      "Epoch 810/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3819 - binary_accuracy: 0.8698 - val_loss: 0.7671 - val_binary_accuracy: 0.7872\n",
      "Epoch 811/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4233 - binary_accuracy: 0.8419 - val_loss: 0.7555 - val_binary_accuracy: 0.7872\n",
      "Epoch 812/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3781 - binary_accuracy: 0.8512 - val_loss: 0.7307 - val_binary_accuracy: 0.7872\n",
      "Epoch 813/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4016 - binary_accuracy: 0.8744 - val_loss: 0.7274 - val_binary_accuracy: 0.7872\n",
      "Epoch 814/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3950 - binary_accuracy: 0.8698 - val_loss: 0.7098 - val_binary_accuracy: 0.7872\n",
      "Epoch 815/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4171 - binary_accuracy: 0.8512 - val_loss: 0.6944 - val_binary_accuracy: 0.7872\n",
      "Epoch 816/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3809 - binary_accuracy: 0.8512 - val_loss: 0.7219 - val_binary_accuracy: 0.7872\n",
      "Epoch 817/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3733 - binary_accuracy: 0.8605 - val_loss: 0.7506 - val_binary_accuracy: 0.7872\n",
      "Epoch 818/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3886 - binary_accuracy: 0.8698 - val_loss: 0.7329 - val_binary_accuracy: 0.7872\n",
      "Epoch 819/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3994 - binary_accuracy: 0.8419 - val_loss: 0.7427 - val_binary_accuracy: 0.7872\n",
      "Epoch 820/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3970 - binary_accuracy: 0.8512 - val_loss: 0.7282 - val_binary_accuracy: 0.7872\n",
      "Epoch 821/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4020 - binary_accuracy: 0.8512 - val_loss: 0.7389 - val_binary_accuracy: 0.7872\n",
      "Epoch 822/10000\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3914 - binary_accuracy: 0.8419 - val_loss: 0.7360 - val_binary_accuracy: 0.7872\n",
      "Epoch 823/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3979 - binary_accuracy: 0.8558 - val_loss: 0.7180 - val_binary_accuracy: 0.7872\n",
      "Epoch 824/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4087 - binary_accuracy: 0.8512 - val_loss: 0.7211 - val_binary_accuracy: 0.7872\n",
      "Epoch 825/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3878 - binary_accuracy: 0.8465 - val_loss: 0.7403 - val_binary_accuracy: 0.7872\n",
      "Epoch 826/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3896 - binary_accuracy: 0.8465 - val_loss: 0.7631 - val_binary_accuracy: 0.7872\n",
      "Epoch 827/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3868 - binary_accuracy: 0.8698 - val_loss: 0.7537 - val_binary_accuracy: 0.7872\n",
      "Epoch 828/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3822 - binary_accuracy: 0.8605 - val_loss: 0.7548 - val_binary_accuracy: 0.7872\n",
      "Epoch 829/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3865 - binary_accuracy: 0.8651 - val_loss: 0.7600 - val_binary_accuracy: 0.7872\n",
      "Epoch 830/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3854 - binary_accuracy: 0.8698 - val_loss: 0.7612 - val_binary_accuracy: 0.7872\n",
      "Epoch 831/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3588 - binary_accuracy: 0.8651 - val_loss: 0.7369 - val_binary_accuracy: 0.7872\n",
      "Epoch 832/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3897 - binary_accuracy: 0.8279 - val_loss: 0.7466 - val_binary_accuracy: 0.7872\n",
      "Epoch 833/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3960 - binary_accuracy: 0.8605 - val_loss: 0.7625 - val_binary_accuracy: 0.7872\n",
      "Epoch 834/10000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4080 - binary_accuracy: 0.8605 - val_loss: 0.7805 - val_binary_accuracy: 0.7872\n",
      "Epoch 835/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4002 - binary_accuracy: 0.8558 - val_loss: 0.7906 - val_binary_accuracy: 0.7872\n",
      "Epoch 836/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3969 - binary_accuracy: 0.8651 - val_loss: 0.7690 - val_binary_accuracy: 0.7872\n",
      "Epoch 837/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3882 - binary_accuracy: 0.8558 - val_loss: 0.7435 - val_binary_accuracy: 0.7872\n",
      "Epoch 838/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3859 - binary_accuracy: 0.8605 - val_loss: 0.7500 - val_binary_accuracy: 0.7872\n",
      "Epoch 839/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4104 - binary_accuracy: 0.8279 - val_loss: 0.7562 - val_binary_accuracy: 0.7872\n",
      "Epoch 840/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3835 - binary_accuracy: 0.8698 - val_loss: 0.7411 - val_binary_accuracy: 0.7872\n",
      "Epoch 841/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4123 - binary_accuracy: 0.8419 - val_loss: 0.7398 - val_binary_accuracy: 0.7872\n",
      "Epoch 842/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4119 - binary_accuracy: 0.8512 - val_loss: 0.7514 - val_binary_accuracy: 0.7872\n",
      "Epoch 843/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3784 - binary_accuracy: 0.8698 - val_loss: 0.7403 - val_binary_accuracy: 0.7872\n",
      "Epoch 844/10000\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4238 - binary_accuracy: 0.8465 - val_loss: 0.7443 - val_binary_accuracy: 0.7872\n",
      "Epoch 845/10000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3973 - binary_accuracy: 0.8605 - val_loss: 0.7227 - val_binary_accuracy: 0.7872\n",
      "Epoch 846/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3837 - binary_accuracy: 0.8605 - val_loss: 0.7245 - val_binary_accuracy: 0.7872\n",
      "Epoch 847/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3768 - binary_accuracy: 0.8651 - val_loss: 0.7380 - val_binary_accuracy: 0.7872\n",
      "Epoch 848/10000\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3732 - binary_accuracy: 0.8465 - val_loss: 0.7411 - val_binary_accuracy: 0.7872\n",
      "Epoch 849/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3928 - binary_accuracy: 0.8605 - val_loss: 0.7648 - val_binary_accuracy: 0.7872\n",
      "Epoch 850/10000\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4026 - binary_accuracy: 0.8558 - val_loss: 0.7482 - val_binary_accuracy: 0.7872\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5018 - binary_accuracy: 0.8043\n",
      "Loss:  0.5018293857574463  Accuracy:  0.804347813129425\n"
     ]
    }
   ],
   "source": [
    "ann = ANNModel();\n",
    "\n",
    "model = ann.fitting();\n",
    "\n",
    "loss, accuracy = model.evaluate(feature_test, label_test);\n",
    "print(\"Loss: \", loss, \" Accuracy: \", accuracy);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
